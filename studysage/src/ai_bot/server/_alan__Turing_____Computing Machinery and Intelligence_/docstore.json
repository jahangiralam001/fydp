[[["2659b0fe-ac12-4d75-ba1a-6347bb42b0d0",{"pageContent":"433 \nVOL. LIX. NO. 236.] [October, 1950 \nM I N D \nA QUARTERLY REVIEW \nOF \nPSYCHOLOGY AND PHILOSOPHY \n \nI.—COMPUTING MACHINERY AND \nINTELLIGENCE \nBY A. M. TURING \n1. The Imitation Game. \nI PROPOSE to consider the question, ‘Can machines think?’ This should \nbegin  with  definitions  of  the  meaning  of  the terms ‘machine’ and \n‘think’.  The  definitions  might  be  framed  so  as  to  reflect  so  far  as \npossible the normal use of the words, but this attitude is dangerous. If \nthe  meaning  of  the  words ‘machine’ and ‘think’ are  to  be  found  by \nexamining  how  they  are  commonly  used  it  is  difficult  to  escape  the \nconclusion  that  the  meaning  and  the  answer  to  the  question, ‘Can \nmachines think?’ is to be sought in a statistical survey such as a Gallup \npoll. But this is absurd. Instead of attempting such a definition I shall \nreplace  the  question  by  another,  which  is  closely  related  to  it  and  is \nexpressed in relatively unambiguous words.","metadata":{"id":0}}],["830f0754-5fe8-43f3-bbf7-66115aa902c5",{"pageContent":"poll. But this is absurd. Instead of attempting such a definition I shall \nreplace  the  question  by  another,  which  is  closely  related  to  it  and  is \nexpressed in relatively unambiguous words. \nThe  new  form  of  the  problem  can  be  described  in  terms  of  a  game \nwhich we call the ‘imitation game’. It is played with three people, a man \n(A), a woman (B), and an interrogator (C) who may be of either sex. The \ninterrogator  stays  in  a  room  apart  from  the  other  two.  The  object  of  the \ngame for the interrogator is to determine which of the other two is the man \nand which is the woman. He knows them by labels X and Y, and at the end \nof the game he says either ‘X is A and Y is B’ or ‘X is B and Y is A’. The \ninterrogator is allowed to put questions to A and B thus: \nC: Will X please tell me the length of his or her hair? \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n434 A. M. TURING:","metadata":{"id":1}}],["7cc4c0c8-a336-40f3-8fd1-1aae4ce1e074",{"pageContent":"C: Will X please tell me the length of his or her hair? \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n434 A. M. TURING: \nNow suppose X is actually A, then A must answer. It is A’s object in the \ngame to try and cause C to make the wrong identification. His answer \nmight therefore be \n‘My  hair  is  shingled,  and  the  longest  strands  are  about  nine  inches \nlong.’ \nIn order that tones of voice may not help the interrogator the answers \nshould be  written, or better still, typewritten. The ideal arrangement is to \nhave a teleprinter communicating between the two rooms. Alternatively the \nquestion and answers can be repeated by an intermediary. The object of the \ngame for the third player (B) is to help the interrogator. The best strategy \nfor her is probably to give truthful answers. She can add such things as ‘I \nam the woman, don’t listen to him!’ to her answers, but it will avail nothing \nas the man can make similar remarks.","metadata":{"id":2}}],["7d9e432f-6c2b-4f9f-8e3b-b7f64aab28e1",{"pageContent":"for her is probably to give truthful answers. She can add such things as ‘I \nam the woman, don’t listen to him!’ to her answers, but it will avail nothing \nas the man can make similar remarks. \nWe  now  ask  the  question, ‘What  will  happen  when  a  machine  takes \nthe part of A in this game?’ Will the interrogator decide wrongly as often \nwhen  the  game  is  played  like  this  as  he  does  when  the  game  is  played \nbetween a man and a woman? These questions replace our original, ‘Can \nmachines think?’ \n2. Critique of the New Problem. \nAs  well  as  asking, ‘What  is  the  answer  to  this  new  form  of  the \nquestion’, one may ask, ‘Is this new question a worthy one to investigate?’ \nThis  latter  question  we  investigate  without  further  ado,  thereby  cutting \nshort an infinite regress. \nThe  new  problem  has  the  advantage  of  drawing  a  fairly  sharp  line \nbetween the physical and the intellectual capacities of a man. No engineer","metadata":{"id":3}}],["5b1b44c6-d992-47b3-a3f9-e406aa9402fe",{"pageContent":"short an infinite regress. \nThe  new  problem  has  the  advantage  of  drawing  a  fairly  sharp  line \nbetween the physical and the intellectual capacities of a man. No engineer \nor chemist   claims   to   be   able   to   produce   a   material   which   is \nindistinguishable from the human skin. It is possible that at some time this \nmight be done, but even supposing this invention available we should feel \nthere was little point in trying to make a ‘thinking machine’ more human \nby dressing it up in such artificial flesh. The form in which we have set the \nproblem reflects this fact in the condition which prevents the interrogator \nfrom  seeing  or  touching  the  other competitors, or  hearing  their  voices. \nSome other  advantages  of  the  proposed  criterion  may  be  shown  up  by \nspecimen questions and answers. Thus: \nQ : Please write me a sonnet on the subject of the Forth Bridge. \nA : Count me out on this one. I never could write poetry. \nQ : Add 34957 to 70764","metadata":{"id":4}}],["a942f608-f2cc-4f75-87fa-a860ae8261a5",{"pageContent":"specimen questions and answers. Thus: \nQ : Please write me a sonnet on the subject of the Forth Bridge. \nA : Count me out on this one. I never could write poetry. \nQ : Add 34957 to 70764 \nA : (Pause about 30 seconds and then give as answer) 105621. \nQ : Do you play chess? \nA : Yes. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 435 \nQ : I have K at my K1, and no other pieces. You have only K at K6 \nand R at R1. It is your move. What do you play? \nA : (After a pause of 15 seconds) R-R8 mate. \nThe question and answer method seems to be suitable for introducing \nalmost any one of the fields of human endeavour that we wish to include. \nWe do not wish to penalise the machine for its inability to shine in beauty \ncompetitions,  nor  to  penalise  a  man  for  losing in  a  race  against  an \naeroplane. The  conditions of  our game  make  these disabilities irrelevant.","metadata":{"id":5}}],["5a21f60c-7622-48f1-9ef3-42455d461cfe",{"pageContent":"competitions,  nor  to  penalise  a  man  for  losing in  a  race  against  an \naeroplane. The  conditions of  our game  make  these disabilities irrelevant. \nThe ‘witnesses’ can  brag,  if  they  consider  it  advisable,  as  much  as  they \nplease about their charms, strength or heroism, but the interrogator cannot \ndemand practical demonstrations. \nThe  game  may perhaps be  criticised on the  ground that  the odds are \nweighted  too  heavily  against  the  machine.  If  the  man  were  to  try  and \npretend to be the machine he would clearly make a very poor showing. He \nwould  be  given  away  at  once by  slowness  and  inaccuracy  in  arithmetic. \nMay  not  machines  carry  out  something  which  ought  to  be  described  as \nthinking but which is very different from what a man does? This objection \nis a very strong one, but at least we can say that if, nevertheless, a machine \ncan be constructed to play the imitation game satisfactorily, we need not be \ntroubled by this objection.","metadata":{"id":6}}],["a4b1b29a-1e32-462f-997c-3942e03c840b",{"pageContent":"is a very strong one, but at least we can say that if, nevertheless, a machine \ncan be constructed to play the imitation game satisfactorily, we need not be \ntroubled by this objection. \nIt  might  be  urged  that  when  playing  the ‘imitation  game’ the  best \nstrategy for the machine may possibly be something other than imitation of \nthe behaviour of a man. This may be, but I think it is unlikely that there is \nany great effect of this kind. In any case there is no intention to investigate \nhere the theory of the game, and it will be assumed that the best strategy is \nto try to provide answers that would naturally be given by a man. \n3. The Machines concerned in the Game. \nThe question which we put in § 1 will not be quite definite until we have \nspecified what we mean by the word ‘machine’. It is natural that we should \nwish  to  permit  every  kind  of  engineering  technique  to  be  used  in  our \nmachines. We also wish to allow the possibility than an engineer or team","metadata":{"id":7}}],["0b2de364-7801-4012-8f16-35c3e5648b9f",{"pageContent":"wish  to  permit  every  kind  of  engineering  technique  to  be  used  in  our \nmachines. We also wish to allow the possibility than an engineer or team \nof engineers may construct a machine which works, but whose manner of \noperation  cannot  be  satisfactorily  described  by  its  constructors  because \nthey have applied a method which is largely experimental. Finally, we wish \nto exclude from the machines men born in the usual manner. It is difficult \nto frame the definitions so as to satisfy these three conditions. One might \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n436 A. M. TURING: \nfor instance insist that the team of engineers should be all of one sex, but \nthis  would  not  really  be  satisfactory,  for  it  is  probably  possible  to  rear  a \ncomplete individual from a single cell of the skin (say) of a man. To do so \nwould be a feat of biological technique deserving of the very highest praise,","metadata":{"id":8}}],["2a0e1c53-0cde-43e7-b036-742c78dbc527",{"pageContent":"complete individual from a single cell of the skin (say) of a man. To do so \nwould be a feat of biological technique deserving of the very highest praise, \nbut  we  would  not  be  inclined  to  regard  it  as  a  case  of ‘constructing  a \nthinking machine’. This prompts us to abandon the requirement that every \nkind of technique should be permitted. We are the more ready to do so in \nview of the  fact that  the  present interest  in ‘thinking  machines’ has been \naroused  by  a  particular  kind  of  machine,  usually  called  an ‘electronic \ncomputer’ or ‘digital computer’. Following this suggestion we only permit \ndigital computers to take part in our game. \nThis restriction appears at  first sight to be  a  very drastic one. I shall \nattempt to show that it is not so in reality. To do this necessitates a short \naccount of the nature and properties of these computers. \nIt  may  also  be  said  that  this  identification  of  machines  with  digital","metadata":{"id":9}}],["9ebb0422-25fc-4051-b0bd-84a99272a36a",{"pageContent":"account of the nature and properties of these computers. \nIt  may  also  be  said  that  this  identification  of  machines  with  digital \ncomputers, like  our criterion for ‘thinking’,  will only be  unsatisfactory if \n(contrary to my belief), it turns out that digital computers are unable to give \na good showing in the game. \nThere are already a number of digital computers in working order, and \nit may be asked, ‘Why not try the experiment straight away? It would be \neasy to satisfy the conditions of the game. A number of interrogators could \nbe used, and statistics compiled to show how often the right identification \nwas given.’ The short answer is that we are not asking whether all digital \ncomputers would do well in the game nor whether the computers at present \navailable would do well, but whether there are imaginable computers which \nwould do well. But this is only the short answer. We shall see this question \nin a different light later. \n4. Digital Computers.","metadata":{"id":10}}],["805e2fdb-693b-4b56-b1bb-d5e9de9f4694",{"pageContent":"would do well. But this is only the short answer. We shall see this question \nin a different light later. \n4. Digital Computers. \nThe idea behind digital computers may be explained by saying that these \nmachines are intended to carry out any operations which could be done by \na human computer. The human computer is supposed to be following fixed \nrules;  he  has  no  authority  to  deviate  from  them  in  any  detail.  We  may \nsuppose that these rules are supplied in a book, which is altered whenever \nhe is put on to a new job. He has also an unlimited supply of paper on which \nhe does his calculations. He may also do his multiplications and additions \non a ‘desk machine’, but this is not important. \nIf we use the above explanation as a definition we shall be in danger \nof circularity of argument. We avoid this by giving an outline of the means \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 437","metadata":{"id":11}}],["8861967b-2598-42d6-8db0-12ea139d60fd",{"pageContent":"Downloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 437 \nby which the desired effect is achieved. A digital computer can usually be \nregarded as consisting of three parts: \n (i) Store. \n (ii) Executive unit. \n(iii) Control. \nThe  store  is  a  store  of  information,  and  corresponds  to  the  human \ncomputer’s  paper,  whether  this  is  the  paper  on  which  he  does  his \ncalculations or that on which his book of rules is printed. In so far as the \nhuman  computer  does  calculations  in  his  head  a  part  of  the  store will \ncorrespond to his memory. \nThe executive unit is the part which carries out the various individual \noperations involved in a calculation. What these individual operations are \nwill vary from machine to machine. Usually fairly lengthy operations can \nbe  done  such  as ‘Multiply  3540675445  by  7076345687’ but  in  some","metadata":{"id":12}}],["b2e62c47-15ed-4012-bfee-169a25ccb015",{"pageContent":"will vary from machine to machine. Usually fairly lengthy operations can \nbe  done  such  as ‘Multiply  3540675445  by  7076345687’ but  in  some \nmachines only very simple ones such as ‘Write down 0’ are possible. \nWe have mentioned that the ‘book of rules’ supplied to the computer \nis replaced in the machine by a part of the store. It is then called the ‘table \nof instructions’. It is the duty of the control to see that these instructions are \nobeyed correctly and in the right order. The control is so constructed that \nthis necessarily happens. \nThe  information  in  the  store  is  usually  broken  up  into  packets  of \nmoderately small size. In one machine, for instance, a packet might consist \nof  ten  decimal  digits.  Numbers  are  assigned  to  the  parts  of  the  store  in \nwhich  the  various  packets  of  information  are  stored,  in  some  systematic \nmanner. A typical instruction might say— \n‘Add the  number stored in position 6809 to that  in 4302 and put the","metadata":{"id":13}}],["87e0c495-b448-4cc2-ad45-a96c004e60a0",{"pageContent":"which  the  various  packets  of  information  are  stored,  in  some  systematic \nmanner. A typical instruction might say— \n‘Add the  number stored in position 6809 to that  in 4302 and put the \nresult back into the latter storage position’. \nNeedless  to  say  it  would  not  occur  in  the  machine  expressed  in \nEnglish. It would more likely be coded in a form such as 6809430217. Here \n17 says which of various possible operations is to be performed on the two \nnumbers. In this case the operation is that described above, viz. ‘Add the \nnumber. . . .’ It will be noticed that the instruction takes up 10 digits and so \nforms  one  packet  of  information,  very  conveniently.  The  control  will \nnormally take the instructions to be obeyed in the order of the positions in \nwhich they are stored, but occasionally an instruction such as \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n438 A. M. TURING:","metadata":{"id":14}}],["613a10f6-5d11-4707-8513-53b3e9d45ca8",{"pageContent":"which they are stored, but occasionally an instruction such as \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n438 A. M. TURING: \n‘Now obey the instruction stored in position 5606, and continue from \nthere’ may be encountered, or again \n‘If position 4505 contains 0 obey next the instruction stored in 6707, \notherwise continue straight on.’ \nInstructions of these latter types are very important because they make \nit possible for a sequence of operations to be repeated over and over again \nuntil  some  condition  is  fulfilled,  but  in  doing  so  to  obey,  not  fresh \ninstructions on each repetition, but the same ones over and over again. To \ntake  a  domestic  analogy.  Suppose  Mother  wants  Tommy  to  call  at  the \ncobbler’s every morning on his way to school to see if her shoes are done, \nshe  can  ask  him  afresh  every  morning.  Alternatively  she  can  stick  up  a","metadata":{"id":15}}],["4a7baf8a-9af6-44f2-95c4-99035e00d23a",{"pageContent":"cobbler’s every morning on his way to school to see if her shoes are done, \nshe  can  ask  him  afresh  every  morning.  Alternatively  she  can  stick  up  a \nnotice  once  and  for  all  in  the  hall  which  he  will  see  when  he  leaves  for \nschool  and  which  tolls  him  to  call  for  the  shoes,  and  also  to  destroy  the \nnotice when he comes back if he has the shoes with him. \nThe  reader  must  accept  it  as  a  fact  that  digital  computers  can  be \nconstructed, and indeed have been constructed, according to the principles \nwe have described, and that they can in fact mimic the actions of a human \ncomputer very closely. \nThe  book  of rules  which  we  have  described  our  human  computer  as \nusing  is  of  course  a  convenient  fiction.  Actual  human  computers  really \nremember what they have got to do. If one wants to make a machine mimic \nthe behaviour of the human computer in some complex operation one has","metadata":{"id":16}}],["6dd5b485-af8e-400b-8edc-2fe8f8164f07",{"pageContent":"remember what they have got to do. If one wants to make a machine mimic \nthe behaviour of the human computer in some complex operation one has \nto ask him how it is done, and then translate the answer into the form of an \ninstruction  table.  Constructing  instruction  tables  is  usually  described  as \n‘programming’.  To ‘programme  a  machine  to  carry  out  the  operation  A’ \nmeans  to  put  the  appropriate  instruction  table  into  the  machine  so  that  it \nwill do A. \nAn  interesting  variant  on  the  idea  of  a  digital  computer  is  a ‘digital \ncomputer  with a  random element’. These have  instructions involving the \nthrowing  of  a  die  or  some  equivalent  electronic  process;  one  such \ninstruction  might  for  instance  be, ‘Throw  the  die  and  put  the  resulting \nnumber into store 1000’. Sometimes such a machine is described as having \nfree  will  (though  I  would  not  use  this  phrase  myself).  It  is  not  normally","metadata":{"id":17}}],["30d3030a-66a0-48dd-a9cb-924e0bd0d076",{"pageContent":"number into store 1000’. Sometimes such a machine is described as having \nfree  will  (though  I  would  not  use  this  phrase  myself).  It  is  not  normally \npossible to determine from observing a  machine  whether it has a random \nelement,  for  a  similar  effect  can  be  produced by  such  devices  as  making \nthe choices depend on the digits of the decimal for π. \nMost  actual  digital  computers  have  only  a  finite  store.  There  is  no \ntheoretical difficulty in the idea of a computer with an unlimited store. Of \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 439 \ncourse only a finite part can have been used at any one time. Likewise only \na finite amount can have been constructed, but we can imagine more and \nmore  being  added  as  required.  Such  computers  have  special  theoretical \ninterest and will be called infinitive capacity computers.","metadata":{"id":18}}],["e14bb6e6-734c-428b-9b3f-0e64f3ccdb81",{"pageContent":"more  being  added  as  required.  Such  computers  have  special  theoretical \ninterest and will be called infinitive capacity computers. \nThe  idea  of  a  digital  computer  is  an  old  one.  Charles  Babbage, \nLucasian  Professor  of  Mathematics  at  Cambridge  from  1828  to  1839, \nplanned  such  a  machine,  called  the  Analytical  Engine,  but  it  was  never \ncompleted. Although Babbage had all the essential ideas, his machine was \nnot  at  that  time  such  a  very  attractive  prospect.  The speed  which  would \nhave been available would be definitely faster than a human computer but \nsomething like 100 times slower than the Manchester machine, itself one \nof  the  slower  of  the  modem  machines.  The  storage  was  to  be  purely \nmechanical, using wheels and cards. \nThe   fact   that   Babbage’s   Analytical   Engine   was   to   be   entirely \nmechanical  will  help  us  to  rid  ourselves  of  a  superstition.  Importance  is","metadata":{"id":19}}],["6a333521-9a32-4b8d-b5f5-b8384f808d79",{"pageContent":"mechanical, using wheels and cards. \nThe   fact   that   Babbage’s   Analytical   Engine   was   to   be   entirely \nmechanical  will  help  us  to  rid  ourselves  of  a  superstition.  Importance  is \noften attached to the fact that modem digital computers are electrical, and \nthat the nervous system also is electrical. Since Babbage’s machine was not \nelectrical, and since all digital computers are in a sense equivalent, we see \nthat  this  use  of electricity cannot be  of theoretical importance. Of course \nelectricity usually comes in where fast signalling is concerned, so that it is \nnot  surprising  that  we  find  it  in  both  these  connections.  In  the  nervous \nsystem  chemical  phenomena  are  at  least  as  important  as  electrical.  In \ncertain  computers  the  storage  system  is  mainly  acoustic.  The  feature  of \nusing electricity is thus seen to be only a very superficial similarity. If we \nwish  to  find  such  similarities  we  should  look  rather  for  mathematical","metadata":{"id":20}}],["55564d28-21cc-46ad-a512-76e60ad54cf1",{"pageContent":"using electricity is thus seen to be only a very superficial similarity. If we \nwish  to  find  such  similarities  we  should  look  rather  for  mathematical \nanalogies of function. \n5. Universality of Digital Computers. \nThe digital computers considered in the last section may be classified \namongst the ‘discrete state machines’. These are the machines which move \nby sudden jumps or clicks from one quite definite state to another. These \nstates  are  sufficiently  different  for the  possibility  of confusion between \nthem  to  be  ignored.  Strictly  speaking  there  are  no  such   machines. \nEverything  really  moves  continuously.  But  there  are  many  kinds  of \nmachine  which  can  profitably  be thought  of as  being  discrete  state \nmachines. For instance in considering the switches for a lighting system it \nis a convenient fiction that each switch must be definitely on or definitely \noff.  There  must  be  intermediate  positions,  but  for  most  purposes  we  can","metadata":{"id":21}}],["3f790a71-75dc-4186-b7f4-f9ef76344881",{"pageContent":"is a convenient fiction that each switch must be definitely on or definitely \noff.  There  must  be  intermediate  positions,  but  for  most  purposes  we  can \nforget  about  them.  As  an  example  of  a  discrete  state  machine  we  might \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n440 A. M. TURING: \nconsider a wheel which clicks round through 120° once a second, but may \nbe  stopped  by  a  lever  which  can  be  operated  from  outside;  in  addition  a \nlamp is to light in one of the positions of the wheel. This machine could be \ndescribed abstractly as follows. The internal state of the machine (which is \ndescribed by the position of the wheel) may be q\n1\n, q\n2\n or q\n3\n. There is an input \nsignal i\n0\n or i\n1\n,  (position  of  lever).  The  internal  state  at  any  moment  is \ndetermined by the last state and input signal according to the table \n Last State \n q\n1 \nq\n2 \nq\n3 \ni\n0 \nq\n2 \nq\n3 \nq\n1 \nInput    \ni\n1 \nq\n1 \nq\n2 \nq\n3","metadata":{"id":22}}],["ab7e8710-0af2-4acb-a93f-a1a75e703484",{"pageContent":"0\n or i\n1\n,  (position  of  lever).  The  internal  state  at  any  moment  is \ndetermined by the last state and input signal according to the table \n Last State \n q\n1 \nq\n2 \nq\n3 \ni\n0 \nq\n2 \nq\n3 \nq\n1 \nInput    \ni\n1 \nq\n1 \nq\n2 \nq\n3 \nThe  output  signals,  the  only  externally  visible  indication  of  the  internal \nstate (the light) are described by the table \nState q\n1 \nq\n2 \nq\n3 \nOutput o\n0 \no\n0 \no\n1 \nThis example is typical of discrete state machines. They can be described \nby such tables provided they have only a finite number of possible states. \nIt  will  seem  that  given  the  initial  state  of  the  machine  and  the  input \nsignals it is always possible to predict all future states. This is reminiscent \nof  Laplace’s  view  that  from  the  complete  state  of  the  universe  at  one \nmoment of time, as described by the positions and velocities of all particles, \nit should be possible to predict all future states. The prediction which we \nare considering  is,  however,  rather  nearer  to  practicability  than  that","metadata":{"id":23}}],["2a2ae1f1-0e4e-4f1d-976f-16b4434b33fd",{"pageContent":"it should be possible to predict all future states. The prediction which we \nare considering  is,  however,  rather  nearer  to  practicability  than  that \nconsidered by Laplace. The system of the ‘universe as a whole’ is such that \nquite small errors in the initial conditions can have an overwhelming effect \nat  a  later  time.  The  displacement  of  a  single  electron  by  a  billionth  of  a \ncentimetre at one moment might make the difference between a man being \nkilled by an avalanche a year later, or escaping. It is an essential property \nof the mechanical systems which we have called ‘discrete state machines’ \nthat  this  phenomenon  does  not  occur.  Even  when  we  consider  the  actual \nphysical  machines instead of the idealised machines, reasonably accurate \nknowledge   of   the   state   at   one   moment   yields   reasonably   accurate \nknowledge any number of steps later. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023","metadata":{"id":24}}],["4faac2d2-73a2-470d-b5d6-51e1efaaa611",{"pageContent":"knowledge any number of steps later. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 441 \nAS we  have  mentioned,  digital computers fall  within  the  class  of \ndiscrete state machines. But the number of states of which such a machine \nis  capable  is  usually  enormously  large.  For  instance,  the  number  for  the \nmachine  now  working  at  Manchester  it  about 2\n165,000,\n i.e. about 10\n50,000\n. \nCompare  this  with  our  example  of  the  clicking  wheel  described  above, \nwhich had three states.  It is not difficult to see  why the  number of  states \nshould be so immense. The computer includes a store corresponding to the \npaper used by a human computer. It must be possible to write into the store \nany one of the combinations of symbols which might have been written on \nthe paper. For simplicity suppose that only digits from 0 to 9 are used as","metadata":{"id":25}}],["1332018f-8c08-4d51-b7a9-27bcbc00e73a",{"pageContent":"any one of the combinations of symbols which might have been written on \nthe paper. For simplicity suppose that only digits from 0 to 9 are used as \nsymbols. Variations in handwriting are ignored. Suppose the computer is \nallowed 100 sheets of paper each containing 50 lines each with room for \n30 digits. Then the number of states is 10\n100×50×30\n, i.e. 10\n150,000\n. This is about \nthe  number  of  states  of  three  Manchester  machines  put  together.  The \nlogarithm  to  the  base  two  of  the  number  of  states  is  usually  called  the \n‘storage  capacity’ of  the  machine.  Thus  the  Manchester  machine  has a \nstorage capacity of about 165,000 and the wheel machine of our example \nabout 1.6. If two machines are put together their capacities must be added \nto obtain the capacity of the resultant machine. This leads to the possibility \nof  statements  such  as ‘The  Manchester  machine  contains  64  magnetic \ntracks each with a capacity of 2560, eight electronic tubes with a capacity","metadata":{"id":26}}],["70886be3-f410-498b-9009-fe10f52b5c09",{"pageContent":"of  statements  such  as ‘The  Manchester  machine  contains  64  magnetic \ntracks each with a capacity of 2560, eight electronic tubes with a capacity \nof  1280.  Miscellaneous  storage  amounts  to  about  300  making  a  total  of \n174,380.’ \nGiven the table corresponding to a discrete state machine it is possible \nto predict what it will do. There is no reason why this calculation should \nnot  be  carried  out  by  means  of  a  digital  computer.  Provided  it  could  be \ncarried  out  sufficiently  quickly  the  digital  computer  could  mimic  the \nbehaviour of any discrete state machine. The imitation game could then be \nplayed  with  the  machine  in  question  (as  B)  and  the  mimicking  digital \ncomputer (as A) and the interrogator would be unable to distinguish them. \nOf course the digital computer must have an adequate storage capacity as \nwell as working sufficiently fast. Moreover, it must be programmed afresh \nfor each new machine which it is desired to mimic.","metadata":{"id":27}}],["fe8c2304-9042-4764-805e-046314c557b9",{"pageContent":"Of course the digital computer must have an adequate storage capacity as \nwell as working sufficiently fast. Moreover, it must be programmed afresh \nfor each new machine which it is desired to mimic. \nThis  special  property  of  digital  computers,  that  they  can  mimic  any \ndiscrete  state  machine,  is  described  by  saying  that  they  are universal \nmachines. The existence of machines with this property has the important \nconsequence that, considerations of speed apart, it is unnecessary to design \nvarious new machines to do various computing processes. They can all be \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n442 A. M. TURING: \ndone with one digital computer, suitably programmed for each case. It will \nbe  seen that as a  consequence of this all digital computers  are  in a  sense \nequivalent. \nWe may now consider again the point raised at the end of §3. It was","metadata":{"id":28}}],["6e15317d-dded-43c9-a00d-c822be7df003",{"pageContent":"be  seen that as a  consequence of this all digital computers  are  in a  sense \nequivalent. \nWe may now consider again the point raised at the end of §3. It was \nsuggested  tentatively  that  the  question, ‘Can  machines  think?’ should  be \nreplaced by ‘Are there imaginable digital computers which would do well \nin  the  imitation  game?’ If  we  wish  we  can  make  this  superficially  more \ngeneral and ask ‘Are there discrete state machines which would do well?’ \nBut in view of the universality property we see that either of these questions \nis  equivalent  to  this, ‘Let  us  fix  our  attention  on  one  particular  digital \ncomputer C. Is it true that by modifying this computer to have an adequate \nstorage,  suitably  increasing  its  speed  of  action,  and  providing  it  with  an \nappropriate programme, C can be made to play satisfactorily the part of A \nin the imitation game, the part of B being taken by a man?’ \n6. Contrary Views on the Main Question.","metadata":{"id":29}}],["58b5cf32-f763-4e4e-bad1-8cce18cd61f8",{"pageContent":"appropriate programme, C can be made to play satisfactorily the part of A \nin the imitation game, the part of B being taken by a man?’ \n6. Contrary Views on the Main Question. \nWe  may  now  consider  the  ground  to  have  been  cleared  and  we  are \nready to proceed to the debate on our question, ‘Can machines think?’ and \nthe variant of it quoted at the end of the last section. We cannot altogether \nabandon the original form of the problem, for opinions will differ as to the \nappropriateness of the substitution and we must at least listen to what has \nto be said in this connexion. \nIt will simplify matters for the reader if I explain first my own beliefs \nin  the  matter.  Consider  first  the  more  accurate  form  of  the  question.  I \nbelieve  that  in  about  fifty  years’ time  it  will  be  possible  to  programme \ncomputers,  with  a  storage  capacity  of  about  10\n9\n,  to  make  them  play  the \nimitation game so well that an average interrogator will not have more than","metadata":{"id":30}}],["5a5289a6-a02b-4289-9322-d45f202d53b1",{"pageContent":"computers,  with  a  storage  capacity  of  about  10\n9\n,  to  make  them  play  the \nimitation game so well that an average interrogator will not have more than \n70 per cent, chance of making the right identification after five minutes of \nquestioning. The original question, ‘Can machines think!’ I believe to be \ntoo  meaningless  to  deserve  discussion.  Nevertheless  I  believe  that  at  the \nend of the century the use of words and general educated opinion will have \naltered so much that one will be able to speak of machines thinking without \nexpecting  to  be  contradicted.  I  believe  further  that  no  useful  purpose  is \nserved by concealing these beliefs. The popular view that scientists proceed \ninexorably from well-established fact to well-established fact, never being \ninfluenced  by  any  unproved  conjecture,  is  quite  mistaken.  Provided  it  is \nmade clear which are proved facts and which are conjectures, no harm can","metadata":{"id":31}}],["083e3d3d-8810-4bc1-8e19-fcfe86275357",{"pageContent":"influenced  by  any  unproved  conjecture,  is  quite  mistaken.  Provided  it  is \nmade clear which are proved facts and which are conjectures, no harm can \nresult. Conjectures are of great importance since they suggest useful lines \nof research. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 443 \nI now proceed to consider opinions opposed to my own. \n(1) The  Theological  Objection. Thinking  is  a  function  of  man’s \nimmortal soul. God has given an immortal soul to every man and woman, \nbut not to any other animal or to machines. Hence no animal or machine \ncan think. \nI  am  unable  to  accept  any  part  of  this,  but  will  attempt  to  reply  in \ntheological terms. I should find the argument more convincing if animals \nwere  classed  with  men,  for  there  is  a  greater  difference,  to  my  mind, \nbetween the typical animate and the inanimate than there is between man","metadata":{"id":32}}],["ab8ca53a-2c71-4d37-8a9b-5ae7809f829f",{"pageContent":"were  classed  with  men,  for  there  is  a  greater  difference,  to  my  mind, \nbetween the typical animate and the inanimate than there is between man \nand  the  other  animals. The  arbitrary  character  of  the  orthodox  view \nbecomes clearer if we consider how it might appear to a member of some \nother religious community. How do Christians regard the Moslem view that \nwomen have  no souls? But let us leave  this point aside  and return  to the \nmain argument. It appears to me that the argument quoted above implies a \nserious restriction of the omnipotence of the Almighty. It is admitted that \nthere are certain things that He cannot do such as making one equal to two, \nbut  should  we  not  believe that  He  has  freedom  to  confer  a  soul  on  an \nelephant if He sees fit? We might expect that He would only exercise this \npower in conjunction with a mutation which provided the elephant with an \nappropriately  improved  brain  to  minister  to  the  needs  of  this  soul.  An","metadata":{"id":33}}],["7790150d-9de5-4111-92cf-ef8cea3fd1a7",{"pageContent":"power in conjunction with a mutation which provided the elephant with an \nappropriately  improved  brain  to  minister  to  the  needs  of  this  soul.  An \nargument of exactly similar form may be made for the case of machines. It \nmay seem different because it is more difficult to “swallow”. But this really \nonly means that we think it would be less likely that He would consider the \ncircumstances suitable for conferring a soul. The circumstances in question \nare  discussed  in  the  rest  of  this  paper.  In  attempting  to  construct  such \nmachines  we  should  not  be  irreverently  usurping  His  power  of  creating \nsouls, any more than we are in the procreation of children: rather we are, \nin either case, instruments of His will providing mansions for the souls that \nHe creates. \nHowever,  this  is  mere  speculation.  I  am  not  very  impressed  with \ntheological  arguments  whatever  they  may  be  used  to  support.  Such","metadata":{"id":34}}],["7b6b6487-e9c0-4b77-8f15-2de55bc7c5ac",{"pageContent":"He creates. \nHowever,  this  is  mere  speculation.  I  am  not  very  impressed  with \ntheological  arguments  whatever  they  may  be  used  to  support.  Such \narguments have often been found unsatisfactory in the past. In the time of \nGalileo it was argued that the texts, “And the sun stood still . . . and hasted \nnot  to  go  down  about  a  whole  day” (Joshua  x.  13)  and “He  laid  the \n                                            \n1\n Possibly this view is heretical. St. Thomas Aquinas (Summa Theologica, \nquoted by Bertrand Russell, p. 480) states that God cannot make a man to \nhave no soul. But this may not be a real restriction on His powers, but only \na  result  of  the  fact  that  men’s  souls   are   immortal,   and   therefore \nindestructible. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n444 A. M. TURING: \nfoundations of the earth, that it should not move at any time” (Psalm cv. 5)","metadata":{"id":35}}],["129c1d7c-36de-41d1-abc1-da546084197d",{"pageContent":"Downloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n444 A. M. TURING: \nfoundations of the earth, that it should not move at any time” (Psalm cv. 5) \nwere  an  adequate  refutation  of  the  Copernican  theory.  With  our  present \nknowledge such an argument appears futile. When that knowledge was not \navailable it made a quite different impression. \n(2) The  ‘Heads  in  the  Sand’  Objection. “The  consequences  of \nmachines thinking would be too dreadful. Let us hope and believe that they \ncannot do so.” \nThis  argument  is  seldom  expressed  quite  so  openly  as  in  the  form \nabove. But it affects most of us who think about it at all. We like to believe \nthat Man is in some subtle way superior to the rest of creation. It is best if \nhe can be shown to be necessarily superior, for then there is no danger of \nhim  losing  his  commanding  position.  The  popularity  of  the  theological","metadata":{"id":36}}],["01a686c6-a858-4d78-bf4d-7bc2a29f6905",{"pageContent":"he can be shown to be necessarily superior, for then there is no danger of \nhim  losing  his  commanding  position.  The  popularity  of  the  theological \nargument is clearly connected with this feeling. It is likely to be quite strong \nin intellectual people, since they value the power of thinking more highly \nthan others, and are more inclined to base their belief in the superiority of \nMan on this power. \nI do not think that this argument is sufficiently substantial to require \nrefutation. Consolation would be more appropriate: perhaps this should be \nsought in the transmigration of souls. \n(3) The  Mathematical  Objection. There  are  a  number  of  results  of \nmathematical logic which can be used to show that there are limitations to \nthe powers of discrete-state  machines. The best known of these results is \nknown  as Gödel’s theorem,\n1\n and  shows  that  in  any  sufficiently  powerful \nlogical system statements can be formulated which can neither be proved","metadata":{"id":37}}],["b7923624-f9cb-449b-9183-9d166f617581",{"pageContent":"known  as Gödel’s theorem,\n1\n and  shows  that  in  any  sufficiently  powerful \nlogical system statements can be formulated which can neither be proved \nnor  disproved  within  the  system,  unless  possibly  the  system  itself  is \ninconsistent.  There  are  other,  in  some  respects  similar,  results  due  to \nChurch,   Kleene, Rosser, and Turing. The   latter   result   is   the   most \nconvenient  to  consider,  since  it  refers  directly  to  machines,  whereas  the \nothers can only be used in a comparatively indirect argument: for instance \nif Gödel’s theorem is to be used we need in addition to have some means \nof describing logical systems in terms of machines, and machines in terms \nof logical systems. The result in question refers to a type of machine which \nis essentially a digital computer with an infinite capacity. It states that there \nare certain things that such a machine cannot do. If it is rigged up to give","metadata":{"id":38}}],["3c8d6b41-0e0f-4e64-9ef4-95f14b8e679e",{"pageContent":"is essentially a digital computer with an infinite capacity. It states that there \nare certain things that such a machine cannot do. If it is rigged up to give \nanswers to questions as in the imitation game, there will be some questions \nto which it will either give a wrong answer, or fail to give an answer at all \nhowever much time is allowed for a reply. There may, of course, be many \n                                            \n1\n Author’s names in italics refer to the Bibliography. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 445 \nsuch questions, and questions which cannot be answered by one machine \nmay be satisfactorily answered by another. We are of course supposing for \nthe present that the questions are of the kind to which an answer ‘Yes’ or \n‘No’ is  appropriate,  rather  than  questions  such  as ‘What  do  you  think  of","metadata":{"id":39}}],["2c88da52-bdb2-4ba3-bf32-e9259373e080",{"pageContent":"the present that the questions are of the kind to which an answer ‘Yes’ or \n‘No’ is  appropriate,  rather  than  questions  such  as ‘What  do  you  think  of \nPicasso?’ The questions that we know the machines must fail on are of this \ntype, “Consider  the  machine  specified  as  follows.  .  .  .  Will  this  machine \never  answer ‘Yes’ to  any  question?” The  dots  are  to  be  replaced  by  a \ndescription of some machine in a standard form, which could be something \nlike  that  used  in  §  5.  When  the  machine  described  bears  a  certain \ncomparatively simple relation to the machine which is under interrogation, \nit can be shown that the answer is either wrong or not forthcoming. This is \nthe mathematical result: it is argued that it proves a disability of machines \nto which the human intellect is not subject. \nThe short answer to this argument is that although it is established that \nthere  are  limitations  to  the  powers  of  any  particular  machine,  it  has  only","metadata":{"id":40}}],["cf7e06d5-7241-465f-97e8-0dce7aeedc99",{"pageContent":"The short answer to this argument is that although it is established that \nthere  are  limitations  to  the  powers  of  any  particular  machine,  it  has  only \nbeen stated, without any sort of proof, that no such limitations apply to the \nhuman  intellect.  But  I  do  not  think  this  view  can  be  dismissed  quite  so \nlightly. Whenever one  of these  machines is asked the  appropriate  critical \nquestion, and  gives a  definite answer,  we  know that  this answer  must be \nwrong,  and  this  gives  us  a  certain  feeling  of  superiority.  Is  this  feeling \nillusory?  It  is  no  doubt  quite  genuine,  but  I  do  not  think  too  much \nimportance should be attached to it. We too often give  wrong answers to \nquestions ourselves to be justified in being very pleased at such evidence \nof fallibility on the part of the machines. Further, our superiority can only \nbe felt on such an occasion in relation to the one machine over which we","metadata":{"id":41}}],["5f9637eb-7551-4c55-b924-aeb8f862db86",{"pageContent":"of fallibility on the part of the machines. Further, our superiority can only \nbe felt on such an occasion in relation to the one machine over which we \nhave scored our petty triumph. There would be no question of triumphing \nsimultaneously  over all machines.  In  short,  then,  there  might  be  men \ncleverer  than  any  given  machine,  but  then  again  there  might  be  other \nmachines cleverer again, and so on. \nThose who hold to the mathematical argument would, I think, mostly \nbe willing to accept the imitation game as a basis for discussion. Those who \nbelieve in the two previous objections would probably not be interested in \nany criteria. \n(4) The  Argument  from  Consciousness. This  argument  is  very  well \nexpressed in Professor Jefferson’s Lister Oration  for 1949, from  which I \nquote. “Not  until  a  machine  can  write  a  sonnet  or  compose  a  concerto \nbecause  of  thoughts  and  emotions  felt,  and  not  by  the  chance  fall  of","metadata":{"id":42}}],["59be1cdf-909b-45e8-81de-6c174f987845",{"pageContent":"quote. “Not  until  a  machine  can  write  a  sonnet  or  compose  a  concerto \nbecause  of  thoughts  and  emotions  felt,  and  not  by  the  chance  fall  of \nsymbols, could we agree that machine equals brain—that is, not only write \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n446 A. M. TURING: \nit but know that it had written it. No mechanism could feel (and not merely \nartificially signal, an easy contrivance) pleasure at its successes, grief when \nits valves fuse, be warmed by flattery, be made miserable by its mistakes, \nbe charmed by sex, be angry or depressed when it cannot get what it wants.” \nThis  argument  appears  to  be  a  denial  of  the  validity  of  our  test. \nAccording to the  most extreme form of this view the only way by  which \none  could  be  sure  that  a  machine  thinks  is  to be the  machine  and  to  feel \noneself thinking. One could then describe these feelings to the world, but","metadata":{"id":43}}],["d38b480b-d1e0-42ab-af8d-07be9a128392",{"pageContent":"one  could  be  sure  that  a  machine  thinks  is  to be the  machine  and  to  feel \noneself thinking. One could then describe these feelings to the world, but \nof  course  no  one  would  be  justified  in  taking  any  notice.  Likewise \naccording to this view the only way to know that a man thinks is to be that \nparticular man. It is in fact the solipsist point of view. It may be the most \nlogical  view  to  hold  but  it  makes  communication  of  ideas  difficult.  A  is \nliable to believe ‘A thinks but B does not’ whilst B believes ‘B thinks but \nA does not’. Instead of arguing continually over this point it is usual to have \nthe polite convention that everyone thinks. \nI am sure that Professor Jefferson does not wish to adopt the extreme \nand solipsist point of view. Probably he  would be quite willing to accept \nthe  imitation  game  as  a  test.  The  game  (with the  player  B omitted)  is \nfrequently used in practice under the name of viva voce to discover whether","metadata":{"id":44}}],["f1362789-eb57-4d22-b0d8-7de56e5b0ee3",{"pageContent":"the  imitation  game  as  a  test.  The  game  (with the  player  B omitted)  is \nfrequently used in practice under the name of viva voce to discover whether \nsome one really understands something or has ‘learnt it parrot fashion’. Let \nus listen in to a part of such a viva voce: \nInterrogator: In the first line of your sonnet which reads ‘Shall I compare \nthee to a summer’s day’, would not ‘a  spring day’ do as well or \nbetter? \nWitness: It wouldn’t scan. \nInterrogator: How about ‘a winter’s day’ That would scan all right. \nWitness: Yes, but nobody wants to be compared to a winter’s day. \nInterrogator: Would you say Mr. Pickwick reminded you of Christmas? \nWitness: In a way. \nInterrogator:  Yet  Christmas  is  a  winter’s  day,  and  I  do  not  think  Mr. \nPickwick would mind the comparison. \nWitness:  I  don’t  think  you’re  serious.  By  a winter’s  flay  one  means  a \ntypical winter’s day, rather than a special one like Christmas.","metadata":{"id":45}}],["df6dae1e-1e78-442b-bab0-e8a9f4777e5d",{"pageContent":"Pickwick would mind the comparison. \nWitness:  I  don’t  think  you’re  serious.  By  a winter’s  flay  one  means  a \ntypical winter’s day, rather than a special one like Christmas. \nAnd so on. What would Professor Jefferson say if the sonnet-writing \nmachine  was  able  to  answer  like  this  in  the viva  voce? I  do  not  know \nwhether  he  would  regard  the  machine  as ‘merely artificially  signalling’ \nthese answers, but if the answers were as satisfactory and sustained as in \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 447 \nthe  above  passage  I  do  not  think  he  would  describe  it  as ‘an  easy \ncontrivance’. This phrase is, I think, intended to cover such devices as the \ninclusion  in  the  machine  of  a  record  of  someone  reading  a  sonnet,  with \nappropriate switching to turn it on from time to time. \nIn short then, I think that most of those who support the argument from","metadata":{"id":46}}],["125f5cda-a38a-4271-b7e7-23b8efbe5ab3",{"pageContent":"appropriate switching to turn it on from time to time. \nIn short then, I think that most of those who support the argument from \nconsciousness could be persuaded to abandon it rather than be forced into \nthe solipsist position. They will then probably be willing to accept our test. \nI do not  wish  to give  the  impression that  I think  there  is no  mystery \nabout  consciousness.  There  is,  for  instance,  something  of  a  paradox \nconnected with any attempt to localise it. But I do not think these mysteries \nnecessarily need to be solved before we can answer the question with which \nwe are concerned in this paper. \n(5) Arguments from  Various  Disabilities. These  arguments  take  the \nform, “I grant you that you can make machines do all the things you have \nmentioned  but  you  will  never  be  able  to  make  one  to  do  X”.  Numerous \nfeatures X are suggested in this connexion. I offer a selection: \nBe kind, resourceful, beautiful, friendly (p. 448), have initiative, have","metadata":{"id":47}}],["22fec7e4-ead8-49ea-8221-66aac413e759",{"pageContent":"features X are suggested in this connexion. I offer a selection: \nBe kind, resourceful, beautiful, friendly (p. 448), have initiative, have \na sense of humour, tell right from  wrong, make  mistakes (p. 448), fall in \nlove,  enjoy  strawberries  and  cream  (p.  448),  make  some  one fall in  love \nwith  it,  learn  from  experience  (pp.  456 f.), use  words  properly,  be  the \nsubject of its own thought (p. 449), have as much diversity of behaviour as \na  man,  do  something  really  new  (p.  450).  (Some  of  these  disabilities  are \ngiven special consideration as indicated by the page numbers.) \nNo support is usually offered for these statements. I believe they are \nmostly  founded  on  the  principle  of  scientific  induction.  A  man  has  seen \nthousands of machines in his lifetime. From what he sees of them he draws \na number of general conclusions. They are ugly, each is designed for a very \nlimited purpose,  when required for a  minutely different purpose  they are","metadata":{"id":48}}],["bc8231e2-a799-4f07-9d79-c27340ebaeb0",{"pageContent":"a number of general conclusions. They are ugly, each is designed for a very \nlimited purpose,  when required for a  minutely different purpose  they are \nuseless, the variety of behaviour of any one of them is very small, etc., etc. \nNaturally he concludes that these are necessary properties of machines in \ngeneral.  Many  of  these  limitations  are  associated  with  the  very  small \nstorage capacity of most machines. (I am assuming that the idea of storage \ncapacity is extended in  some  way to cover  machines other  than discrete-\nstate  machines. The  exact  definition  does  not  matter  as  no  mathematical \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n448 A. M. TURING: \naccuracy is claimed in the present discussion.) A few years ago, when very \nlittle  had  been  heard  of  digital  computers,  it  was  possible  to  elicit  much \nincredulity  concerning  them,  if  one  mentioned  their  properties  without","metadata":{"id":49}}],["9febdc4a-df4f-45d0-80ab-19a9c43c1310",{"pageContent":"little  had  been  heard  of  digital  computers,  it  was  possible  to  elicit  much \nincredulity  concerning  them,  if  one  mentioned  their  properties  without \ndescribing  their  construction.  That  was  presumably  due  to  a  similar \napplication  of  the  principle  of  scientific  induction.  These  applications  of \nthe principle are of course largely unconscious. When a burnt child fears \nthe fire and shows that he fears it by avoiding it, I should say that he was \napplying scientific induction. (I could of course also describe his behaviour \nin many other ways.) The works and customs of mankind do not seem to \nbe  very  suitable  material  to  which  to  apply  scientific  induction.  A  very \nlarge  part of space-time  must be  investigated, if reliable  results are  to be \nobtained.  Otherwise  we  may  (as  most  English  children  do)  decide  that \neverybody speaks English, and that it is silly to learn French.","metadata":{"id":50}}],["4a82be9c-9457-4b32-ba75-71f9d1dfd508",{"pageContent":"obtained.  Otherwise  we  may  (as  most  English  children  do)  decide  that \neverybody speaks English, and that it is silly to learn French. \nThere  are,  however,  special  remarks  to  be  made  about  many  of  the \ndisabilities that  have  been  mentioned. The  inability to enjoy  strawberries \nand  cream  may  have  struck  the  reader  as  frivolous.  Possibly  a  machine \nmight be made to enjoy this delicious dish, but any attempt to make one do \nso  would  be  idiotic.  What  is  important  about  this  disability  is  that  it \ncontributes  to  some of  the  other  disabilities, e.g. to  the  difficulty  of  the \nsame kind of friendliness occurring between man and machine as between \nwhite man and white man, or between black man and black man. \nThe claim that “machines cannot make mistakes” seems a curious one. \nOne is tempted to retort, “Are they any the worse for that?” But let us adopt \na more sympathetic attitude, and try to see what is really meant. I think this","metadata":{"id":51}}],["201593c6-1b7c-47dc-b706-098f78425f9d",{"pageContent":"One is tempted to retort, “Are they any the worse for that?” But let us adopt \na more sympathetic attitude, and try to see what is really meant. I think this \ncriticism can be explained in terms of the imitation game. It is claimed that \nthe  interrogator  could  distinguish  the  machine  from  the  man  simply  by \nsetting them a  number of problems in arithmetic. The  machine  would be \nunmasked because of its deadly accuracy. The reply to this is simple. The \nmachine (programmed for playing the game) would not attempt to give the \nright answers to the  arithmetic  problems. It  would deliberately introduce \nmistakes in a manner calculated to confuse the interrogator. A mechanical \nfault would probably show itself through an unsuitable decision as to what \nsort of a mistake to make in the arithmetic. Even this interpretation of the \ncriticism is not sufficiently sympathetic. But we cannot afford the space to","metadata":{"id":52}}],["dc1cb6f2-e91b-4178-a8b5-a5f79b507a34",{"pageContent":"sort of a mistake to make in the arithmetic. Even this interpretation of the \ncriticism is not sufficiently sympathetic. But we cannot afford the space to \ngo  into  it  much  further.  It  seems  to  me  that  this  criticism  depends on  a \nconfusion  between  two  kinds  of  mistake.  We  may  call them ‘errors  of \nfunctioning’ and ‘errors  of  conclusion’.  Errors  of  functioning  are  due  to \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 449 \nsome  mechanical  or  electrical  fault  which  causes  the  machine  to  behave \notherwise than it was designed to do. In philosophical discussions one likes \nto ignore the possibility of such errors; one is therefore discussing ‘abstract \nmachines’. These abstract machines are mathematical fictions rather than \nphysical objects. By definition they are incapable of errors of functioning.","metadata":{"id":53}}],["ab13b5a1-8d22-4952-bf14-ad134404f1cd",{"pageContent":"machines’. These abstract machines are mathematical fictions rather than \nphysical objects. By definition they are incapable of errors of functioning. \nIn  this  sense  we  can  truly  say  that ‘machines  can  never  make  mistakes’. \nErrors of conclusion can only arise when some meaning is attached to the \noutput signals from the machine. The machine might, for instance, type out \nmathematical equations, or sentences in English. When a false proposition \nis  typed  we  say  that  the  machine  has  committed  an  error  of  conclusion. \nThere is clearly no reason at all for saying that a machine cannot make this \nkind  of  mistake.  It  might  do  nothing  but  type  out  repeatedly ‘0  =  1’.  To \ntake  a  less  perverse  example,  it  might  have  some  method  for  drawing \nconclusions by scientific induction. We must expect such a method to lead \noccasionally to erroneous results. \nThe claim that a machine cannot be the subject of its own thought can","metadata":{"id":54}}],["32942ac9-b372-4cc5-afae-3cf845130eeb",{"pageContent":"conclusions by scientific induction. We must expect such a method to lead \noccasionally to erroneous results. \nThe claim that a machine cannot be the subject of its own thought can \nof course only be answered if it can be shown that the machine has some \nthought  with some subject  matter.  Nevertheless, ‘the  subject  matter  of  a \nmachine’s operations’ does seem to mean something, at least to the people \nwho deal with it. If, for instance, the machine was trying to find a solution \nof the  equation x\n2\n − 40x − 11 =  0 one  would be  tempted to describe  this \nequation as part of the machine’s subject matter at that moment. In this sort \nof sense a  machine undoubtedly can be its own subject matter. It may be \nused to help in making up its own programmes, or to predict the effect of \nalterations  in  its  own  structure.  By  observing  the  results  of  its  own \nbehaviour it can modify its own programmes so as to achieve some purpose","metadata":{"id":55}}],["a4b89ea7-e3e7-4810-a034-3d901fb5f8e3",{"pageContent":"alterations  in  its  own  structure.  By  observing  the  results  of  its  own \nbehaviour it can modify its own programmes so as to achieve some purpose \nmore  effectively.  These  are  possibilities  of  the  near  future,  rather  than \nUtopian dreams. \nThe criticism that a machine cannot have much diversity of behaviour \nis  just  a  way  of  saying  that  it  cannot  have  much  storage  capacity.  Until \nfairly recently a storage capacity of even a thousand digits was very rare. \nThe criticisms that we are considering here are often disguised forms \nof  the  argument  from  consciousness.  Usually  if  one  maintains  that  a \nmachine can do one of these things, and describes the kind of method that \nthe  machine  could  use,  one  will  not  make much  of  an  impression.  It is \nthought that the method (whatever it may be, for it must be mechanical) is \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n450 A. M. TURING:","metadata":{"id":56}}],["053f71c4-9bca-4b54-ac9e-37e29dbea569",{"pageContent":"thought that the method (whatever it may be, for it must be mechanical) is \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n450 A. M. TURING: \nreally rather base. Compare the parenthesis in Jefferson’s statement quoted \non p. 21. \n(6) Lady  Lovelace’s  Objection. Our  most  detailed  information  of \nBabbage’s Analytical Engine comes from a memoir by Lady Lovelace. In \nit  she  states, “The  Analytical  Engine  has  no  pretensions  to originate \nanything.  It  can  do whatever  we  know  how  to  order  it to  perform” (her \nitalics). This statement is quoted by Hartree (p. 70) who adds: “This does \nnot  imply  that  it  may  not  be possible to  construct  electronic  equipment \nwhich will ‘think for itself’, or in which, in biological terms, one could set \nup  a  conditioned  reflex,  which  would  serve  as  a  basis  for ‘learning’. \nWhether  this  is  possible  in principle  or  not  is  a  stimulating  and  exciting","metadata":{"id":57}}],["412ff4b1-9412-4230-9fc6-162d3b381bc5",{"pageContent":"up  a  conditioned  reflex,  which  would  serve  as  a  basis  for ‘learning’. \nWhether  this  is  possible  in principle  or  not  is  a  stimulating  and  exciting \nquestion, suggested by some  of these recent developments. But it did not \nseem  that  the  machines  constructed  or  projected  at  the  time  had  this \nproperty”. \nI am in thorough agreement with Hartree over this. It will be noticed \nthat  be  does  not  assert  that  the  machines  in  question  had  not  got  the \nproperty, but rather that  the  evidence available  to Lady  Lovelace  did not \nencourage  her  to  believe that  they  had  it.  It  is  quite  possible  that  the \nmachines  in  question  had in  a  sense  got  this  property.  For  suppose  that \nsome discrete-state machine has the property. The Analytical Engine was \na universal digital computer, so that, if its storage capacity and speed were \nadequate, it could by suitable programming be made to mimic the machine","metadata":{"id":58}}],["25c591cb-717e-44cf-a8c8-6a5930f471c1",{"pageContent":"a universal digital computer, so that, if its storage capacity and speed were \nadequate, it could by suitable programming be made to mimic the machine \nin  question.  Probably  this  argument  did  not  occur  to  the  Countess  or  to \nBabbage. In any case there was no obligation on them to claim all that could \nbe claimed. \nThis  whole  question  will  be  considered  again  under  the  heading  of \nlearning machines. \nA  variant  of  Lady  Lovelace’s  objection  states  that  a  machine  can \n‘never do anything really new’. This may be parried for a moment with the \nsaw, ‘There is nothing new under the sun’. Who can be certain that ‘original \nwork’ that he  has done  was not simply the  growth of the  seed planted in \nhim by teaching, or the effect of following well-known general principles. \nA better variant of the objection says that a machine can never ‘take us by \nsurprise’. This statement is a more direct challenge and can be met directly.","metadata":{"id":59}}],["4e0f46d3-087a-4db5-b811-95c038ed96bd",{"pageContent":"A better variant of the objection says that a machine can never ‘take us by \nsurprise’. This statement is a more direct challenge and can be met directly. \nMachines take me by surprise with great frequency. This is largely because \nI do not do sufficient calculation to decide  what to expect them to do, or \nrather  because,  although  I  do  a  calculation,  I  do  it  in  a  hurried,  slipshod \nfashion, taking risks. Perhaps I say to myself, ‘I suppose the voltage here \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 451 \nought to be  the  same  as there: anyway let’s assume  it is.’ Naturally I am \noften  wrong,  and  the  result  is  a  surprise  for  me  for  by  the  time  the \nexperiment   is   done   these   assumptions   have   been   forgotten.   These \nadmissions lay me open to lectures on the subject of my vicious ways, but","metadata":{"id":60}}],["56454ad8-4f66-446e-b294-e461560554cb",{"pageContent":"experiment   is   done   these   assumptions   have   been   forgotten.   These \nadmissions lay me open to lectures on the subject of my vicious ways, but \ndo not throw any doubt on my credibility when I testify to the surprises I \nexperience. \nI do not expect this reply to silence my critic. He will probably say that \nsuch surprises are due to some creative mental act on my part, and reflect \nno  credit  on  the  machine.  This  leads  us  back  to  the  argument  from \nconsciousness, and far from the idea of surprise. It is a line of argument we \nmust   consider   closed,   but   it   is   perhaps   worth   remarking   that   the \nappreciation  of  something  as  surprising  requires  as  much  of  a ‘creative \nmental act’ whether the surprising event originates from a man, a book, a \nmachine or anything else. \nThe view that machines cannot give rise to surprises is due, I believe, \nto  a  fallacy  to  which  philosophers  and  mathematicians  are  particularly","metadata":{"id":61}}],["30fb5f3d-5c45-4b26-9544-641fb97cf36a",{"pageContent":"machine or anything else. \nThe view that machines cannot give rise to surprises is due, I believe, \nto  a  fallacy  to  which  philosophers  and  mathematicians  are  particularly \nsubject. This is the assumption that as soon as a fact is presented to a mind \nall consequences of that fact spring into the mind simultaneously with it. It \nis a very useful assumption under many circumstances, but one too easily \nforgets that it is false. A natural consequence of doing so is that one then \nassumes  that  there  is  no  virtue  in  the  mere  working  out  of  consequences \nfrom data and general principles. \n(7) Argument  from  Continuity in  the  Nervous  System. The  nervous \nsystem  is  certainly  not  a  discrete-state  machine.  A  small  error  in  the \ninformation  about  the  size  of  a  nervous  impulse  impinging  on  a  neuron, \nmay make a large difference to the size of the outgoing impulse. It may be \nargued  that,  this  being  so,  one  cannot  expect  to  be  able  to  mimic  the","metadata":{"id":62}}],["aa954f10-8a7b-4a52-9c16-3da3407f61b5",{"pageContent":"may make a large difference to the size of the outgoing impulse. It may be \nargued  that,  this  being  so,  one  cannot  expect  to  be  able  to  mimic  the \nbehaviour of the nervous system with a discrete-state system. \nIt  is  true  that  a  discrete-state  machine  must  be  different  from  a \ncontinuous  machine.  But  if  we  adhere  to  the  conditions  of  the imitation \ngame,  the  interrogator  will  not  be  able  to  take  any  advantage  of  this \ndifference.  The  situation  can  be  made  clearer  if  we  consider  some  other \nsimpler continuous machine. A differential analyser will do very well. (A \ndifferential analyser is a  certain kind of  machine  not of the discrete-state \ntype  used  for  some  kinds  of  calculation.)  Some  of  these  provide  their \nanswers in a typed form, and so are suitable for taking part in the game. It \nwould  not  be  possible  for  a  digital  computer  to  predict  exactly  what","metadata":{"id":63}}],["247ef71f-b9a3-4064-8cef-6c4bef1dfdf0",{"pageContent":"answers in a typed form, and so are suitable for taking part in the game. It \nwould  not  be  possible  for  a  digital  computer  to  predict  exactly  what \nanswers the differential analyser would give to a problem, but it would be \nquite capable  of giving the  right  sort of answer. For instance, if asked to \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n452 A. M. TURING: \ngive the value of π (actually about 3.1416) it would be reasonable to choose \nat random  between  the  values  3.12,  3.13,  3.14,  3.15,  3.16  with  the \nprobabilities   of   0.05,   0.15,   0.55,   0.19,   0.06   (say).   Under   these \ncircumstances it would be very difficult for the interrogator to distinguish \nthe differential analyser from the digital computer. \n(8) The Argument from Informality of Behaviour. It is not possible to \nproduce a set of rules purporting to describe what a man should do in every","metadata":{"id":64}}],["e315e94e-2790-43b2-a678-2fe9367e8805",{"pageContent":"the differential analyser from the digital computer. \n(8) The Argument from Informality of Behaviour. It is not possible to \nproduce a set of rules purporting to describe what a man should do in every \nconceivable set of circumstances. One might for instance have a rule that \none is to stop when one sees a red traffic light, and to go if one sees a green \none,  but  what  if  by  some  fault  both  appear  together?  One  may  perhaps \ndecide that it is safest to stop. But some  further difficulty may well arise \nfrom  this  decision  later.  To  attempt  to  provide  rules  of  conduct  to  cover \nevery  eventuality,  even  those  arising  from  traffic  lights,  appears  to  be \nimpossible. With all this I agree. \nFrom  this  it  is  argued  that  we  cannot  be  machines.  I  shall  try  to \nreproduce the argument, but I fear I shall hardly do it justice. It seems to \nrun something like this. ‘If each man had a definite set of rules of conduct","metadata":{"id":65}}],["0bbfd05b-2ccd-4b80-83ec-933190f52977",{"pageContent":"reproduce the argument, but I fear I shall hardly do it justice. It seems to \nrun something like this. ‘If each man had a definite set of rules of conduct \nby which be regulated his life he would be no better than a machine. But \nthere  are  no  such  rules,  so  men  cannot  be  machines.’ The  undistributed \nmiddle is glaring. I do not think the argument is ever put quite like this, bat \nI believe this is the argument used nevertheless. There may however be a \ncertain  confusion  between ‘rules  of  conduct’ and ‘laws  of  behaviour’ to \ncloud the issue. By ‘rules of conduct’ I mean precepts such as ‘Stop if you \nsee red lights’, on which one can act, and of which one can be conscious. \nBy ‘laws of behaviour’ I mean laws of nature as applied to a man’s body \nsuch  as ‘if  you  pinch  him  he  will  squeak’.  If  we  substitute ‘laws  of \nbehaviour  which  regulate his  life’ for ‘laws  of  conduct  by  which  he","metadata":{"id":66}}],["10f18a33-fc37-4af5-a8e1-2338409ec025",{"pageContent":"such  as ‘if  you  pinch  him  he  will  squeak’.  If  we  substitute ‘laws  of \nbehaviour  which  regulate his  life’ for ‘laws  of  conduct  by  which  he \nregulates  his  life’ in  the  argument  quoted  the undistributed  middle  is  no \nlonger  insuperable.  For  we  believe  that  it  is  not  only  true  that  being \nregulated by laws of behaviour implies being some sort of machine (though \nnot necessarily a discrete-state machine), but that conversely being such a \nmachine  implies  being  regulated  by  such  laws.  However,  we  cannot  so \neasily convince ourselves of the absence of complete laws of behaviour as \nof complete rules of conduct. The only way we know of for finding such \nlaws is scientific observation, and we certainly know of no circumstances \nunder which we could say, ‘We have searched enough. There are no such \nlaws.’ \nWe can demonstrate more forcibly that any such statement would be \nunjustified.  For  suppose  we  could  be  sure  of  finding such  laws  if  they","metadata":{"id":67}}],["cf5df36a-7032-40bd-855f-1091ad69d642",{"pageContent":"laws.’ \nWe can demonstrate more forcibly that any such statement would be \nunjustified.  For  suppose  we  could  be  sure  of  finding such  laws  if  they \nexisted. Then given a discrete-state machine it should certainly be possible \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 453 \nto discover by observation sufficent about it to predict its future behaviour, \nand this within a reasonable time, say a thousand years. But this does not \nseem  to  be  the  case.  I  have  set  up  on  the  Manchester  computer  a  small \nprogramme  using  only  1000  units  of  storage,  whereby  the  machine \nsupplied  with  one  sixteen  figure  number  replies  with  another  within  two \nseconds. I would defy anyone to learn from these replies sufficient about \nthe programme to be able to predict any replies to untried values. \n(9) The  Argument  from  Extra-Sensory  Perception. I  assume  that  the","metadata":{"id":68}}],["d3e02788-ebdd-4d97-a868-e8da528f599d",{"pageContent":"the programme to be able to predict any replies to untried values. \n(9) The  Argument  from  Extra-Sensory  Perception. I  assume  that  the \nreader  is  familiar  with  the  idea  of  extra-sensory  perception,  and  the \nmeaning of the four items of it, viz. telepathy, clairvoyance, precognition \nand  psycho-kinesis.  These  disturbing  phenomena  seem  to  deny  all  our \nusual scientific ideas. How we should like to discredit them! Unfortunately \nthe  statistical  evidence, at  least for telepathy, is overwhelming. It is very \ndifficult to rearrange one’s ideas so as to fit these new facts in. Once one \nhas accepted them it does not seem a very big step to believe in ghosts and \nbogies. The idea that our bodies move simply according to the known laws \nof  physics,  together  with  some  others  not  yet  discovered  but  somewhat \nsimilar, would be one of the first to go. \nThis argument is to my mind quite a strong one. One can say in reply","metadata":{"id":69}}],["d3a883ac-00e9-42d6-ad43-acc763274613",{"pageContent":"of  physics,  together  with  some  others  not  yet  discovered  but  somewhat \nsimilar, would be one of the first to go. \nThis argument is to my mind quite a strong one. One can say in reply \nthat many scientific theories seem to remain workable in practice, in spite \nof  clashing  with  E.S.P.;  that  in  fact  one  can  get  along  very  nicely  if  one \nforgets about it. This is rather cold comfort, and one fears that thinking is \njust the kind of phenomenon where E.S.P. may be especially relevant. \nA more specific argument based on E.S.P. might run as follows: “Let \nus  play  the  imitation  game,  using  as  witnesses  a  man  who  is  good  as  a \ntelepathic receiver, and a digital computer. The interrogator can ask such \nquestions as ‘What suit does the card in my right hand belong to?’ The man \nby telepathy or clairvoyance gives the  right answer 130 times out of 400 \ncards. The machine can only guess at random, and perhaps gets 104 right,","metadata":{"id":70}}],["1948fb45-68f1-4ecb-86d7-de09f0db3553",{"pageContent":"by telepathy or clairvoyance gives the  right answer 130 times out of 400 \ncards. The machine can only guess at random, and perhaps gets 104 right, \nso the interrogator makes the right identification.” There is an interesting \npossibility  which  opens  here.  Suppose  the  digital  computer  contains  a \nrandom number generator. Then it will be natural to use this to decide what \nanswer to give. But then the random number generator will be subject to \nthe psycho-kinetic powers of the interrogator. Perhaps this psycho-kinesis \nmight cause the machine to guess right more often than would be expected \non a probability calculation, so that the interrogator might still be unable to \nmake the right identification. On the other hand, he might be able to guess \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n454 A. M. TURING: \nright without any questioning, by clairvoyance. With E.S.P. anything may \nhappen.","metadata":{"id":71}}],["bb455d4b-af10-472e-a6a8-5710d025ef73",{"pageContent":"Downloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n454 A. M. TURING: \nright without any questioning, by clairvoyance. With E.S.P. anything may \nhappen. \nIf telepathy is admitted it will be necessary to tighten our test up. The \nsituation could be regarded as analogous to that which would occur if the \ninterrogator  were  talking  to  himself  and  one  of  the  competitors  was \nlistening with his ear to the wall. To put the competitors into a ‘telepathy-\nproof room’ would satisfy all requirements. \n7. Learning Machines. \nThe  reader  will  have  anticipated  that  I  have  no  very  convincing \narguments of a positive nature to support my views. If I had I should not \nhave  taken  such  pains  to  point  out  the  fallacies  in  contrary  views.  Such \nevidence as I have I shall now give. \nLet us return for a moment to Lady Lovelace’s objection, which stated \nthat the machine can only do what we tell it to do. One could say that a man","metadata":{"id":72}}],["a649eace-b828-4a80-a403-3280075705a9",{"pageContent":"evidence as I have I shall now give. \nLet us return for a moment to Lady Lovelace’s objection, which stated \nthat the machine can only do what we tell it to do. One could say that a man \ncan ‘inject’ an idea into the  machine, and that it will respond to a certain \nextent  and  then  drop  into  quiescence,  like  a  piano  string  struck  by  a \nhammer. Another simile would be an atomic pile of less than critical size: \nan injected idea is to correspond to a neutron entering the pile from without. \nEach such neutron will cause  a certain disturbance which eventually dies \naway.  If,  however,  the  size  of  the  pile  is  sufficiently  increased,  the \ndisturbance caused by such an incoming neutron will very likely go on and \non  increasing  until  the  whole  pile  is  destroyed.  Is  there  a  corresponding \nphenomenon for minds, and is there one for machines? There does seem to \nbe one for the human mind. The majority of them seem to be ‘sub-critical’,","metadata":{"id":73}}],["8bd39e03-8238-48b4-a5a6-74f4e77114f1",{"pageContent":"phenomenon for minds, and is there one for machines? There does seem to \nbe one for the human mind. The majority of them seem to be ‘sub-critical’, \ni.e. to  correspond  in  this  analogy  to  piles  of  sub-critical  size.  An  idea \npresented to such a mind will on average give rise to less than one idea in \nreply. A smallish proportion are super-critical. An idea presented to such a \nmind  may  give  rise  to  a  whole ‘theory’ consisting  of  secondary,  tertiary \nand  more  remote  ideas.  Animals  minds  seem  to  be  very  definitely  sub-\ncritical. Adhering to this analogy  we  ask, ‘Can a  machine  be  made  to be \nsuper-critical?’ \nThe ‘skin  of  an  onion’ analogy  is  also  helpful.  In  considering  the \nfunctions of the mind or the brain we find certain operations which we can \nexplain in purely mechanical terms. This we say does not correspond to the \nreal mind: it is a sort of skin which we must strip off if we are to find the","metadata":{"id":74}}],["7931eea6-9eb4-46c7-83bc-e66682a02f3f",{"pageContent":"explain in purely mechanical terms. This we say does not correspond to the \nreal mind: it is a sort of skin which we must strip off if we are to find the \nreal mind. But then in what remains we find a further skin to be stripped \noff, and so on. Proceeding in this way do we ever come to the ‘real’ mind, \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 455 \nor do we eventually come to the skin which has nothing in it? In the latter \ncase  the  whole  mind  is  mechanical.  (It  would  not  be  a  discrete-state \nmachine however. We have discussed this.) \nThese last two paragraphs do not claim to be  convincing arguments. \nThey should rather be described as ‘recitations tending to produce belief’. \nThe  only  really  satisfactory  support  that  can  be  given  for  the  view \nexpressed at the beginning of § 6, will be that provided by waiting for the","metadata":{"id":75}}],["50e6d9e9-3cc8-4117-87df-c9133ac41e57",{"pageContent":"The  only  really  satisfactory  support  that  can  be  given  for  the  view \nexpressed at the beginning of § 6, will be that provided by waiting for the \nend of the century and then doing the experiment described. But what can \nwe say in the meantime? What steps should be taken now if the experiment \nis to be successful? \nAs  I  have  explained,  the  problem  is  mainly  one  of  programming. \nAdvances in engineering  will have  to be  made  too, but it seems  unlikely \nthat  these  will  not  be  adequate  for  the  requirements.  Estimates  of  the \nstorage capacity of the brain vary from 10\n10 \nto 10\n15\n binary digits. I incline \nto the lower values and believe that only a very small fraction is used for \nthe higher types of thinking. Most of it is probably used for the retention of \nvisual impressions. I should be surprised if more than 10\n9\n was required for \nsatisfactory playing of the imitation game, at any rate against a blind man.","metadata":{"id":76}}],["ec47c11f-3fdb-4f11-b5aa-a73bac178e41",{"pageContent":"visual impressions. I should be surprised if more than 10\n9\n was required for \nsatisfactory playing of the imitation game, at any rate against a blind man. \n(Note—The capacity of the Encyclopaedia Britannica, 11th edition, is 2 × \n10\n9\n.) A storage capacity of 10\n7 \nwould be a very practicable possibility even \nby present techniques. It is probably not necessary to increase the speed of \noperations of the machines at all. Parts of modem machines which can be \nregarded  as  analogues  of  nerve  cells  work  about  a  thousand  times  faster \nthan the latter. This should provide a ‘margin of safety’ which could cover \nlosses of speed arising in many ways. Our problem then is to find out how \nto  programme  these  machines  to  play  the  game.  At  my  present  rate  of \nworking  I  produce  about  a  thousand  digits  of  programme  a  day,  so  that \nabout  sixty  workers,  working  steadily  through  the  fifty  years  might \naccomplish the job, if nothing went into the waste-paper basket. Some more","metadata":{"id":77}}],["42900f6b-5256-498b-b5f4-6856d4e95d59",{"pageContent":"about  sixty  workers,  working  steadily  through  the  fifty  years  might \naccomplish the job, if nothing went into the waste-paper basket. Some more \nexpeditious method seems desirable. \nIn the process of trying to imitate an adult human mind we are bound \nto think a good deal about the process which has brought it to the state that \nit is in. We may notice three components, \n(a) The initial state of the mind, say at birth, \n(b) The education to which it has been subjected, \n(c) Other experience, not to be described as education, to which it has \nbeen subjected. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n456 A. M. TURING: \nInstead of trying to produce a programme to simulate the adult mind, \nwhy not rather try to produce one which simulates the child’s? If this were \nthen subjected to an appropriate course of education one would obtain the \nadult  brain.  Presumably  the  child-brain  is  something like a  note-book  as","metadata":{"id":78}}],["e4810923-5a7f-4903-ad33-092b27dccfde",{"pageContent":"then subjected to an appropriate course of education one would obtain the \nadult  brain.  Presumably  the  child-brain  is  something like a  note-book  as \none buys it from the stationers. Rather little mechanism, and lots of blank \nsheets.  (Mechanism  and  writing  are  from  our  point  of  view  almost \nsynonymous.)  Our  hope  is  that  there  is  so  little  mechanism  in  the  child-\nbrain that something like it can be easily programmed. The amount of work \nin the education we can assume, as a first approximation, to be much the \nsame as for the human child. \nWe have   thus   divided   our   problem   into   two   parts.   The   child-\nprogramme  and  the  education  process.  These  two  remain  very  closely \nconnected.  We  cannot  expect  to  find  a  good  child-machine  at  the  first \nattempt. One must experiment with teaching one such machine and see how \nwell it learns. One can then try another and see if it is better or worse. There","metadata":{"id":79}}],["47a15f02-c59f-476b-90b5-ac11bef24b64",{"pageContent":"attempt. One must experiment with teaching one such machine and see how \nwell it learns. One can then try another and see if it is better or worse. There \nis  an  obvious  connection  between  this  process  and  evolution,  by  the \nidentifications \nStructure of the child machine = Hereditary material \nChanges „  „ = Mutations \nNatural selection = Judgment of the experimenter \nOne  may  hope,  however,  that  this  process  will  be  more  expeditious  than \nevolution.  The  survival  of  the  fittest  is  a  slow  method  for  measuring \nadvantages.  The  experimenter,  by  the  exercise  of  intelligence,  should be \nable to speed it up. Equally important is the fact that he is not restricted to \nrandom  mutations.  If  he  can  trace  a  cause  for  some  weakness  he  can \nprobably think of the kind of mutation which will improve it. \nIt  will  not  be  possible  to  apply  exactly  the same  teaching  process  to \nthe machine as to a normal child. It will not, for instance, be provided with","metadata":{"id":80}}],["cf9ec487-a712-4177-8025-23656c42cf2e",{"pageContent":"It  will  not  be  possible  to  apply  exactly  the same  teaching  process  to \nthe machine as to a normal child. It will not, for instance, be provided with \nlegs, so that it could not be asked to go out and fill the coal scuttle. Possibly \nit  might  not  have  eyes.  But  however  well  these  deficiencies  might  be \novercome by clever engineering, one could not send the creature to school \nwithout the other children making excessive fun of it. It must be given some \ntuition.  We  need  not  be  too  concerned  about  the  legs,  eyes,  etc.  The \nexample of Miss Helen Keller shows that education can take place provided \nthat communication in both directions between teacher and pupil can take \nplace by some means or other. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 457 \nWe  normally  associate  punishments  and  rewards  with  the  teaching","metadata":{"id":81}}],["0e878e22-f61f-47ff-ad5a-aaed0594622c",{"pageContent":"COMPUTING MACHINERY AND INTELLIGENCE 457 \nWe  normally  associate  punishments  and  rewards  with  the  teaching \nprocess. Some  simple  child-machines can be  constructed or programmed \non this sort of principle. The machine has to be so constructed that events \nwhich shortly preceded the occurrence of a punishment-signal are unlikely \nto  be  repeated,  whereas  a  reward-signal  increased  the  probability  of \nrepetition  of  the  events  which  led  up  to  it.  These  definitions  do  not \npresuppose  any  feelings  on  the  part  of  the  machine.  I  have  done  some \nexperiments with one such child-machine, and succeeded in teaching it a \nfew things, but the teaching method was too unorthodox for the experiment \nto be considered really successful. \nThe  use  of  punishments  and  rewards  can  at  best  be  a  part  of  the \nteaching process. Roughly speaking, if the teacher has no other means of \ncommunicating  to  the  pupil,  the  amount  of  information  which  can  reach","metadata":{"id":82}}],["e1870a15-be29-49a8-941d-97d6a546eb67",{"pageContent":"teaching process. Roughly speaking, if the teacher has no other means of \ncommunicating  to  the  pupil,  the  amount  of  information  which  can  reach \nhim does not exceed the total number of rewards and punishments applied. \nBy  the  time  a  child  has  learnt  to  repeat ‘Casabianca’ he  would  probably \nfeel  very  sore  indeed,  if  the  text  could  only  be  discovered  by  a ‘Twenty \nQuestions’ technique, every ‘NO’ taking the form of a blow. It is necessary \ntherefore to have some other ‘unemotional’ channels of communication. If \nthese  are  available  it  is  possible  to  teach  a  machine  by  punishments  and \nrewards to obey orders given in some language, e.g. a symbolic language. \nThese orders are to be transmitted through the ‘unemotional’ channels. The \nuse of this language will diminish greatly the number of punishments and \nrewards required. \nOpinions may vary as to the complexity which is suitable in the child","metadata":{"id":83}}],["76b43b93-ef3e-4eea-be7d-3973bcbabe13",{"pageContent":"use of this language will diminish greatly the number of punishments and \nrewards required. \nOpinions may vary as to the complexity which is suitable in the child \nmachine. One might try to make it as simple as possible consistently with \nthe general principles. Alternatively one might have a complete system of \nlogical  inference ‘built  in’.\n1 \nIn  the  latter  case  the  store  would  be  largely \noccupied with definitions and propositions. The  propositions  would have \nvarious    kinds    of    status, e.g. well-established    facts,    conjectures, \nmathematically   proved   theorems,   statements   given   by   an   authority, \nexpressions  having  the  logical  form  of  proposition  but  not  belief-value. \nCertain  propositions  may  be  described  as ‘imperatives’.  The  machine \nshould be so constructed that as soon as an imperative is classed as ‘well-\nestablished’ the appropriate action automatically takes place. To illustrate","metadata":{"id":84}}],["c40a66da-a6ba-4518-a9e6-2c16b5841e76",{"pageContent":"should be so constructed that as soon as an imperative is classed as ‘well-\nestablished’ the appropriate action automatically takes place. To illustrate \nthis, suppose the teacher says to the machine, ‘Do your homework now’. \nThis may cause “Teacher says ‘Do your homework now’” to be included \n                                            \n1\n Or rather ‘programmed in’ for our child-machine will be programmed in \na digital computer. But the logical system will not have to be learnt. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n458 A. M. TURING: \namongst   the   well-established   facts.   Another   such   fact   might   be, \n“Everything  that  teacher  says  is true”.  Combining  these  may  eventually \nlead to the imperative, ‘Do your homework now’, being included amongst \nthe well-established facts, and this, by the construction of the machine, will \nmean  that  the  homework  actually  gets  started,  but  the  effect  is  very","metadata":{"id":85}}],["163ffe4e-456c-49d3-9b66-f8377a41261e",{"pageContent":"the well-established facts, and this, by the construction of the machine, will \nmean  that  the  homework  actually  gets  started,  but  the  effect  is  very \nsatisfactory. The processes of inference used by the  machine need not be \nsuch as would satisfy the most exacting logicians. There might for instance \nbe  no  hierarchy  of  types.  But  this  need  not  mean  that  type  fallacies  will \noccur,  any  more  than  we  are  bound  to  fall  over  unfenced  cliffs.  Suitable \nimperatives (expressed within the systems, not forming part of the rules of \nthe system) such as ‘Do not use a class unless it is a subclass of one which \nhas been mentioned by teacher’ can have a similar effect to ‘Do not go too \nnear the edge’. \nThe imperatives that can be obeyed by a machine that has no limbs are \nbound  to  be  of  a  rather  intellectual  character,  as  in  the  example  (doing \nhomework) given above. Important amongst such imperatives will be ones","metadata":{"id":86}}],["a4db0375-68a9-46c2-9838-fe5422dc00cc",{"pageContent":"bound  to  be  of  a  rather  intellectual  character,  as  in  the  example  (doing \nhomework) given above. Important amongst such imperatives will be ones \nwhich regulate the order in which the rules of the logical system concerned \nare to be applied. For at each stage when one is using a logical system, there \nis a very large number of alternative steps, any of which one is permitted \nto apply, so far as obedience to the rules of the logical system is concerned. \nThese  choices  make  the  difference  between  a  brilliant  and  a  footling \nreasoner,  not  the  difference  between  a  sound  and  a  fallacious  one. \nPropositions leading to imperatives of this kind might be “When Socrates \nis  mentioned,  use  the  syllogism  in  Barbara” or “If  one  method  has  been \nproved to be quicker than another, do not use the slower method”. Some of \nthese  may  be ‘given  by  authority’,  but  others  may  be  produced  by  the \nmachine itself, e.g. by scientific induction.","metadata":{"id":87}}],["08db1e39-8c02-4387-aa8c-eaf3d0bafe48",{"pageContent":"proved to be quicker than another, do not use the slower method”. Some of \nthese  may  be ‘given  by  authority’,  but  others  may  be  produced  by  the \nmachine itself, e.g. by scientific induction. \nThe  idea  of  a  learning  machine  may  appear  paradoxical  to  some \nreaders.  How  can  the  rules  of  operation  of  the  machine  change?  They \nshould describe completely how the machine will react whatever its history \nmight be, whatever changes it might undergo. The rules are thus quite time-\ninvariant. This is quite true. The explanation of the paradox is that the rules \nwhich get changed in the learning process are of a rather less pretentious \nkind, claiming only an ephemeral validity. The reader may draw a parallel \nwith the Constitution of the United States. \nAn important feature of a learning machine is that its teacher will often \nbe very largely ignorant of quite what is going on inside, although he may","metadata":{"id":88}}],["58841f7c-54f1-4b28-87b8-290e14349450",{"pageContent":"with the Constitution of the United States. \nAn important feature of a learning machine is that its teacher will often \nbe very largely ignorant of quite what is going on inside, although he may \nstill  be  able  to  some  extent  to  predict  his  pupil’s  behaviour.  This  should \napply most strongly to the later education of a machine arising from a child-\nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n COMPUTING MACHINERY AND INTELLIGENCE 459 \nmachine of well-tried design (or programme). This is in clear contrast with \nnormal procedure when using a machine to do computations: one’s object \nis then to have  a clear  mental picture  of the  state  of the  machine at  each \nmoment  in  the  computation.  This  object  can  only  be  achieved  with  a \nstruggle.  The  view  that ‘the  machine  can  only  do  what  we  know  how  to \norder  it  to  do’,\n1\n appears  strange  in  face  of  this.  Most  of  the  programmes","metadata":{"id":89}}],["864fd575-cfe4-43a2-b025-08249e5a9499",{"pageContent":"struggle.  The  view  that ‘the  machine  can  only  do  what  we  know  how  to \norder  it  to  do’,\n1\n appears  strange  in  face  of  this.  Most  of  the  programmes \nwhich we can put into the machine will result in its doing something that \nwe cannot make sense of at all, or which we regard as completely random \nbehaviour. Intelligent behaviour presumably consists in a  departure  from \nthe completely disciplined behaviour involved in computation, but a rather \nslight one,  which does not give  rise  to random behaviour, or to pointless \nrepetitive loops. Another important result of preparing our machine for its \npart  in  the  imitation  game  by  a  process  of  teaching  and  learning  is that \n‘human  fallibility’ is  likely  to  be  omitted  in  a  rather  natural  way, i.e. \nwithout special ‘coaching’. (The reader should reconcile this with the point \nof view on pp. 24, 25.) Processes that are learnt do not produce a hundred","metadata":{"id":90}}],["e56c261a-5daf-4450-8936-0502c5672302",{"pageContent":"without special ‘coaching’. (The reader should reconcile this with the point \nof view on pp. 24, 25.) Processes that are learnt do not produce a hundred \nper cent. certainty of result; if they did they could not be unlearnt. \nIt is probably wise to include a random element in a learning machine \n(see p. 438). A random element is rather useful when we are searching for \na  solution  of  some,  problem.  Suppose  for  instance  we  wanted  to  find  a \nnumber between 50 and 200 which was equal to the square of the sum of \nits digits, we might start at 51 then try 52 and go on until we got a number \nthat  worked.  Alternatively  we  might choose  numbers at  random  until  we \ngot a a good one. This method has the advantage that it is unnecessary to \nkeep track of the values that have been tried, but the disadvantage that one \nmay  try  the  same  one  twice,  but  this  is  not  very  important  if  there  are \nseveral  solutions.  The  systematic  method  has  the  disadvantage  that there","metadata":{"id":91}}],["b2572ae6-820d-4293-9626-dd2626778518",{"pageContent":"may  try  the  same  one  twice,  but  this  is  not  very  important  if  there  are \nseveral  solutions.  The  systematic  method  has  the  disadvantage  that there \nmay be an enormous block without any solutions in the region which has \nto  be  investigated  first.  Now  the  learning  process  may  be  regarded  as  a \nsearch for a form of behaviour which will satisfy the teacher (or some other \ncriterion).  Since  there  is  probably  a  very  large  number  of  satisfactory \nsolutions  the  random  method  seems  to  be  better  than  the  systematic.  It \nshould be noticed that it is used in the analogous process of evolution. But \nthere the systematic method is not possible. How could one keep track of \n                                            \n1\n Compare Lady Lovelace’s statement (p. 450), which does not contain the \nword ‘only’. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n460 A. M. TURING:","metadata":{"id":92}}],["34efcad0-f5c4-4d07-af78-6a18599c774e",{"pageContent":"word ‘only’. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023\n460 A. M. TURING: \nthe  different genetical combinations  that  had  been  tried,  so  as  to  avoid \ntrying them again? \nWe may hope that machines will eventually compete with men in all \npurely intellectual fields. But which are the best ones to start with? Even \nthis is a difficult decision. Many people think that a very abstract activity, \nlike the playing of chess, would be best. It can also be maintained that it is \nbest to provide the machine with the best sense organs that money can buy, \nand  then  teach  it  to  understand  and  speak  English.  This  process  could \nfollow  the  normal  teaching  of  a  child.  Things  would  be  pointed  out  and \nnamed, etc. Again I do not know what the right answer is, but I think both \napproaches should be tried. \nWe  can only  see a  short distance ahead, but  we  can see plenty  there \nthat needs to be done. \nBIBLIOGRAPHY","metadata":{"id":93}}],["22eb473e-4980-4c91-9119-69ace951d4d0",{"pageContent":"approaches should be tried. \nWe  can only  see a  short distance ahead, but  we  can see plenty  there \nthat needs to be done. \nBIBLIOGRAPHY \nSamuel Butler, Erewhon, London, 1865. Chapters 23, 24, 25, The Book of \nthe Machines. \nAlonzo Church, “An Unsolvable Problem of Elementary Number Theory”, \nAmerican J. of Math., 58 (1936), 345-363. \nK. Gödel, “Über formal unentscheildbare Sätze der Principia Mathematica \nund  verwandter  Systeme, I”, Monatshefle  für  Math,  und  Phys., \n(1931), 173-189. \nD. R. Hartree, Calculating Instruments and Machines, New York, 1949. \nS.   C.   Kleene, “General Recursive Functions of Natural Numbers”, \nAmerican J. of Math., 57 (1935), 153-173 and 219-244. \nG. Jefferson, “The  Mind  of  Mechanical Man”.  Lister  Oration  for  1949. \nBritish Medical Journal, vol. i (1949), 1105-1121. \nCountess  of  Lovelace, ‘Translator’s  notes  to  an  article  on  Babbage’s \nAnalytical Engiro’, Scientific Memoirs (ed. by R. Taylor), vol. 3 \n(1842), 691-731.","metadata":{"id":94}}],["30e93a9b-5533-4fa5-aac8-7cc66dfc7991",{"pageContent":"Countess  of  Lovelace, ‘Translator’s  notes  to  an  article  on  Babbage’s \nAnalytical Engiro’, Scientific Memoirs (ed. by R. Taylor), vol. 3 \n(1842), 691-731. \nBertrand Russell, History of Western Philosophy, London, 1940. \nA.  M.  Turing, “On  Computable  Numbers,  with  an  Application  to  the \nEntscheidungsproblem”, Proc. London Math. Soc. (2), 42 (1937), \n230-265. \nVictoria University of Manchester. \nDownloaded from https://academic.oup.com/mind/article/LIX/236/433/986238 by guest on 03 December 2023","metadata":{"id":95}}]],{"0":"2659b0fe-ac12-4d75-ba1a-6347bb42b0d0","1":"830f0754-5fe8-43f3-bbf7-66115aa902c5","2":"7cc4c0c8-a336-40f3-8fd1-1aae4ce1e074","3":"7d9e432f-6c2b-4f9f-8e3b-b7f64aab28e1","4":"5b1b44c6-d992-47b3-a3f9-e406aa9402fe","5":"a942f608-f2cc-4f75-87fa-a860ae8261a5","6":"5a21f60c-7622-48f1-9ef3-42455d461cfe","7":"a4b1b29a-1e32-462f-997c-3942e03c840b","8":"0b2de364-7801-4012-8f16-35c3e5648b9f","9":"2a0e1c53-0cde-43e7-b036-742c78dbc527","10":"9ebb0422-25fc-4051-b0bd-84a99272a36a","11":"805e2fdb-693b-4b56-b1bb-d5e9de9f4694","12":"8861967b-2598-42d6-8db0-12ea139d60fd","13":"b2e62c47-15ed-4012-bfee-169a25ccb015","14":"87e0c495-b448-4cc2-ad45-a96c004e60a0","15":"613a10f6-5d11-4707-8513-53b3e9d45ca8","16":"4a7baf8a-9af6-44f2-95c4-99035e00d23a","17":"6dd5b485-af8e-400b-8edc-2fe8f8164f07","18":"30d3030a-66a0-48dd-a9cb-924e0bd0d076","19":"e14bb6e6-734c-428b-9b3f-0e64f3ccdb81","20":"6a333521-9a32-4b8d-b5f5-b8384f808d79","21":"55564d28-21cc-46ad-a512-76e60ad54cf1","22":"3f790a71-75dc-4186-b7f4-f9ef76344881","23":"ab7e8710-0af2-4acb-a93f-a1a75e703484","24":"2a2ae1f1-0e4e-4f1d-976f-16b4434b33fd","25":"4faac2d2-73a2-470d-b5d6-51e1efaaa611","26":"1332018f-8c08-4d51-b7a9-27bcbc00e73a","27":"70886be3-f410-498b-9009-fe10f52b5c09","28":"fe8c2304-9042-4764-805e-046314c557b9","29":"6e15317d-dded-43c9-a00d-c822be7df003","30":"58b5cf32-f763-4e4e-bad1-8cce18cd61f8","31":"5a5289a6-a02b-4289-9322-d45f202d53b1","32":"083e3d3d-8810-4bc1-8e19-fcfe86275357","33":"ab8ca53a-2c71-4d37-8a9b-5ae7809f829f","34":"7790150d-9de5-4111-92cf-ef8cea3fd1a7","35":"7b6b6487-e9c0-4b77-8f15-2de55bc7c5ac","36":"129c1d7c-36de-41d1-abc1-da546084197d","37":"01a686c6-a858-4d78-bf4d-7bc2a29f6905","38":"b7923624-f9cb-449b-9183-9d166f617581","39":"3c8d6b41-0e0f-4e64-9ef4-95f14b8e679e","40":"2c88da52-bdb2-4ba3-bf32-e9259373e080","41":"cf7e06d5-7241-465f-97e8-0dce7aeedc99","42":"5f9637eb-7551-4c55-b924-aeb8f862db86","43":"59be1cdf-909b-45e8-81de-6c174f987845","44":"d38b480b-d1e0-42ab-af8d-07be9a128392","45":"f1362789-eb57-4d22-b0d8-7de56e5b0ee3","46":"df6dae1e-1e78-442b-bab0-e8a9f4777e5d","47":"125f5cda-a38a-4271-b7e7-23b8efbe5ab3","48":"22fec7e4-ead8-49ea-8221-66aac413e759","49":"bc8231e2-a799-4f07-9d79-c27340ebaeb0","50":"9febdc4a-df4f-45d0-80ab-19a9c43c1310","51":"4a82be9c-9457-4b32-ba75-71f9d1dfd508","52":"201593c6-1b7c-47dc-b706-098f78425f9d","53":"dc1cb6f2-e91b-4178-a8b5-a5f79b507a34","54":"ab13b5a1-8d22-4952-bf14-ad134404f1cd","55":"32942ac9-b372-4cc5-afae-3cf845130eeb","56":"a4b89ea7-e3e7-4810-a034-3d901fb5f8e3","57":"053f71c4-9bca-4b54-ac9e-37e29dbea569","58":"412ff4b1-9412-4230-9fc6-162d3b381bc5","59":"25c591cb-717e-44cf-a8c8-6a5930f471c1","60":"4e0f46d3-087a-4db5-b811-95c038ed96bd","61":"56454ad8-4f66-446e-b294-e461560554cb","62":"30fb5f3d-5c45-4b26-9544-641fb97cf36a","63":"aa954f10-8a7b-4a52-9c16-3da3407f61b5","64":"247ef71f-b9a3-4064-8cef-6c4bef1dfdf0","65":"e315e94e-2790-43b2-a678-2fe9367e8805","66":"0bbfd05b-2ccd-4b80-83ec-933190f52977","67":"10f18a33-fc37-4af5-a8e1-2338409ec025","68":"cf5df36a-7032-40bd-855f-1091ad69d642","69":"d3e02788-ebdd-4d97-a868-e8da528f599d","70":"d3a883ac-00e9-42d6-ad43-acc763274613","71":"1948fb45-68f1-4ecb-86d7-de09f0db3553","72":"bb455d4b-af10-472e-a6a8-5710d025ef73","73":"a649eace-b828-4a80-a403-3280075705a9","74":"8bd39e03-8238-48b4-a5a6-74f4e77114f1","75":"7931eea6-9eb4-46c7-83bc-e66682a02f3f","76":"50e6d9e9-3cc8-4117-87df-c9133ac41e57","77":"ec47c11f-3fdb-4f11-b5aa-a73bac178e41","78":"42900f6b-5256-498b-b5f4-6856d4e95d59","79":"e4810923-5a7f-4903-ad33-092b27dccfde","80":"47a15f02-c59f-476b-90b5-ac11bef24b64","81":"cf9ec487-a712-4177-8025-23656c42cf2e","82":"0e878e22-f61f-47ff-ad5a-aaed0594622c","83":"e1870a15-be29-49a8-941d-97d6a546eb67","84":"76b43b93-ef3e-4eea-be7d-3973bcbabe13","85":"c40a66da-a6ba-4518-a9e6-2c16b5841e76","86":"163ffe4e-456c-49d3-9b66-f8377a41261e","87":"a4db0375-68a9-46c2-9838-fe5422dc00cc","88":"08db1e39-8c02-4387-aa8c-eaf3d0bafe48","89":"58841f7c-54f1-4b28-87b8-290e14349450","90":"864fd575-cfe4-43a2-b025-08249e5a9499","91":"e56c261a-5daf-4450-8936-0502c5672302","92":"b2572ae6-820d-4293-9626-dd2626778518","93":"34efcad0-f5c4-4d07-af78-6a18599c774e","94":"22eb473e-4980-4c91-9119-69ace951d4d0","95":"30e93a9b-5533-4fa5-aac8-7cc66dfc7991"}]