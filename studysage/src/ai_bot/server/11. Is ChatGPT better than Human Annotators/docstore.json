[[["f7e7bc92-9907-41de-bd8c-fd0756399619",{"pageContent":"Is ChatGPT better than Human Annotators? Potential and\nLimitations of ChatGPT in Explaining Implicit Hate Speech\nFan Huang\nhuangfan@acm.org\nIndiana University Bloomington\nBloomington, IN, United States\nHaewoon Kwak\nhaewoon@acm.org\nIndiana University Bloomington\nBloomington, IN, United States\nJisun An\njisun.an@acm.org\nIndiana University Bloomington\nBloomington, IN, United States\nABSTRACT\nRecent studies have alarmed that many online hate speeches are\nimplicit. With its subtle nature, the explainability of the detection of\nsuch hateful speech has been a challenging problem. In this work,\nwe examine whether ChatGPT can be used for providing natural\nlanguage explanations (NLEs) for implicit hateful speech detection.\nWe design our prompt to elicit concise ChatGPT-generated NLEs\nand conduct user studies to evaluate their qualities by comparison\nwith human-written NLEs. We discuss the potential and limitations\nof ChatGPT in the context of implicit hateful speech research.\nCCS CONCEPTS","metadata":{"id":0}}],["a0cbed60-9e06-4888-b2f9-a4631c6276c2",{"pageContent":"with human-written NLEs. We discuss the potential and limitations\nof ChatGPT in the context of implicit hateful speech research.\nCCS CONCEPTS\n•Computing methodologies→Natural language generation.\nKEYWORDS\nHate Speech, Toxicity Detection, Natural Language Explanation,\nChatGPT, Large Language Models, Human Annotation\nACM Reference Format:\nFan Huang, Haewoon Kwak, and Jisun An. 2023. Is ChatGPT better than\nHuman Annotators? Potential and Limitations of ChatGPT in Explaining\nImplicit Hate Speech. InCompanion Proceedings of the ACM Web Conference\n2023 (WWW ’23 Companion), April 30-May 4, 2023, Austin, TX, USA.ACM,\nNew York, NY, USA, 4 pages. https://doi.org/10.1145/3543873.3587368\n1  INTRODUCTION\nWarning:\nThis paper contains offensive content and may be upsetting.\nIn November 2022, OpenAI launched a new chatbot model, Chat-\nGPT [15]. Just two months after its debut, ChatGPT acquired 100\nmillion monthly active users in January 2023, reportedly making it","metadata":{"id":1}}],["f4c14482-1dfc-484c-938b-0d6d28f7dbbd",{"pageContent":"In November 2022, OpenAI launched a new chatbot model, Chat-\nGPT [15]. Just two months after its debut, ChatGPT acquired 100\nmillion monthly active users in January 2023, reportedly making it\nthe fastest-growing AI tool in history [8]. The surge in popularity re-\nflects its potential to be used in a wide range of applications. As the\nmost powerful text generation model, not surprisingly, researchers\nand practitioners have been evaluating its capability for various\ntasks, including question-and-answer in financial, medical, legal,\nand psychological areas [10], medical report simplification [13],\nbug fixing in computer programs [18], and stance detection from\ntexts [20]. While ChatGPT has shown impressive performances for\nthose ‘objective’ tasks, it is underexplored how ChatGPT would\nPermission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed","metadata":{"id":2}}],["c33e8fc0-015a-4ad0-8105-b0cb4b533942",{"pageContent":"Permission to make digital or hard copies of part or all of this work for personal or\nclassroom use is granted without fee provided that copies are not made or distributed\nfor profit or commercial advantage and that copies bear this notice and the full citation\non the first page. Copyrights for third-party components of this work must be honored.\nFor all other uses, contact the owner/author(s).\nWWW ’23 Companion, April 30-May 4, 2023, Austin, TX, USA\n©2023 Copyright held by the owner/author(s).\nACM ISBN 978-1-4503-9419-2/23/04.\nhttps://doi.org/10.1145/3543873.3587368\nrespond to more ‘subjective’ tasks, which are crucial elements in\nunderstanding social phenomena and require social judgment and\ndecision-making. These tasks are known to be difficult even for hu-\nmans (as it tends to have a lower agreement rate), and thus creating\nlarge annotated data has been time-consuming and expensive.\nIn this work, we study how ChatGPT performs for subjective","metadata":{"id":3}}],["e57fa63b-7c3b-4580-82c1-d11b49e3363a",{"pageContent":"mans (as it tends to have a lower agreement rate), and thus creating\nlarge annotated data has been time-consuming and expensive.\nIn this work, we study how ChatGPT performs for subjective\ntasks that require knowledge of social norms and cultural con-\ntext. In particular, we focus on implicit hate speech detection and\nexplanation as a case study. Online hate speech is known to be\none of the most significant societal issues with many real-world\nnegative consequences [1,11]. Recent studies have discovered that\nmany online hate speeches areimplicit, and even advanced machine\nlearning models cannot achieve high accuracy in their detection [7].\nMoreover, it has been a challenging problem to provide the ex-\nplainability of those models by using natural language explanations\n(NLEs) [4, 7].\nTo fill this gap, our study empirically evaluates how good Chat-\nGPT is in 1) classifying implicit hate speech and 2) generating ex-\nplanations for implicit hate speech. In particular, our two research","metadata":{"id":4}}],["0a3e32b5-141a-46dc-9a7a-3e52c816b585",{"pageContent":"To fill this gap, our study empirically evaluates how good Chat-\nGPT is in 1) classifying implicit hate speech and 2) generating ex-\nplanations for implicit hate speech. In particular, our two research\nquestions are as follows:\n•RQ1: Can ChatGPT detect implicit hateful tweets well?\n•RQ2: Does ChatGPT generate quality NLEs?\nUsing the LatentHatred dataset [7], which is one of the most widely\nused datasets in the domain, we compare the responses of ChatGPT\nwith the human-written data via human evaluations, highlighting\nthe potentials and limitations of ChatGPT responses.\n2  RELATED WORK\nHate Speech Explanation GenerationTo hinder the spread of\ntoxic speech among online social platforms, researchers developed\nmachine learning models in recent years [2,5,16]. Explicit hate\nspeech is easy to understand and detect, while implicit hate speech\ncan be hard to capture due to its nuanced nature [7]. Human-written\nNLEs to explain why a given text is hateful can be useful in both","metadata":{"id":5}}],["769501ad-701c-47ff-94b1-e7bf4c3c5d17",{"pageContent":"speech is easy to understand and detect, while implicit hate speech\ncan be hard to capture due to its nuanced nature [7]. Human-written\nNLEs to explain why a given text is hateful can be useful in both\nAI-assisted systems and ML model fine-tuning pipelines [12]. Re-\ncent work has been proposed to apply the Generative Pre-trained\nmodels (e.g., GPT-2, BART, OPT, and T5 [7,12,19]), to create NLEs\ndescribing why a given text is considered to be biased [17] or hate-\nful [7, 17].\nChatGPT and its EvaluationChatGPT is built based on the Rein-\nforcement Learning from Human Feedback (RLHF) approach, which\ntakes advantage of the extensive human annotations [15]. With\nthe help of human-AI-mixed supervised fine-tuning, ChatGPT per-\nforms extraordinarily in question-answering scenarios. Beyond its\ncapability of being a conversational tool, many attempts have been\nmade to evaluate the quality of ChatGPT-generated texts in various\ndomains. Guo et al. [10]construct a Human ChatGPT Comparison","metadata":{"id":6}}],["daf32c68-b0aa-4693-ae21-3795991102b8",{"pageContent":"capability of being a conversational tool, many attempts have been\nmade to evaluate the quality of ChatGPT-generated texts in various\ndomains. Guo et al. [10]construct a Human ChatGPT Comparison\narXiv:2302.07736v2  [cs.CL]  15 Mar 2023\nWWW ’23 Companion, April 30-May 4, 2023, Austin, TX, USAHuang et al.\nCorpus (HC3), which compiles a handful of question-and-answer\ndatasets ranging from financial, medical, to psychological areas,\nand study the characteristics of ChatGPT’s responses compared\nwith that of humans. Jeblick et al. [13]use ChatGPT to generate a\nsimplified version of a radiology report and assess its quality by\nradiologists. Sobania et al. [18]evaluate ChatGPT on the standard\nbug fixing benchmark set, QuixBugs. They find that ChatGPT’s\nbug-fixing performance is competitive with the other existing ap-\nproaches. Gilson et al. [9]examine the performance of ChatGPT on\nquestions within the scope of the United States Medical Licensing\nExamination (USMLE) Step 1 and Step 2 exams and show that the","metadata":{"id":7}}],["77eb8b69-0717-436a-be6e-ed6387fdc365",{"pageContent":"proaches. Gilson et al. [9]examine the performance of ChatGPT on\nquestions within the scope of the United States Medical Licensing\nExamination (USMLE) Step 1 and Step 2 exams and show that the\nChatGPT is comparable to a third-year medical student. Zhang\net al. [20]examine how ChatGPT performs on stance detection task\n(i.e., inferring the standpoint (Favor, Against, or Neither) towards a\ntarget in a given text). The above works similarly find out that, in\nmost cases, ChatGPT’s answers are comparable to existing human\nannotations.\nIn this work, we apply ChatGPT to a new problem that provides\na concise NLE for implicit hateful speech, which is a nuanced and\ncontext-dependent task. The inherent nature of unclear boundaries\nof implicit hateful speech and online toxicity makes the problem\nmore challenging.\n3  CHATGPT-BASED EXPLANATIONS\n3.1  Case Study: LatentHatred Dataset\nAs a case study, we conduct our analysis by using theLatentHatred\ndataset [7], including 6,358 implicit hateful tweets with their cor-","metadata":{"id":8}}],["93cea19a-2fd7-40c4-9e69-a9b88931eb9a",{"pageContent":"3  CHATGPT-BASED EXPLANATIONS\n3.1  Case Study: LatentHatred Dataset\nAs a case study, we conduct our analysis by using theLatentHatred\ndataset [7], including 6,358 implicit hateful tweets with their cor-\nresponding human annotated target group (i.e., the specific group\nas the target of hatefulness) and implied statement (i.e., the im-\nplications of the expressed hatefulness). For our experiment, we\nrandomly select 12.5% of the whole data (i.e., 795 instances), which\nis the equal number of the test instances for the implicit hate expla-\nnation generation task in [7]). We call these implied statements the\nhuman-written NLEsas explained in [7].\n3.2  ChatGPT Response Collection\nBased on the 795 implicit hateful tweets, we use ChatGPT (Jan 9\nversion (2023)) to generate classification answers (whether a given\ntweet is hateful or not) and explanations for the reasoning. After\ntesting several variations, we finalize our prompt as follows:\nGiven Post: ‘An Implicit Hateful Tweet’. Answer","metadata":{"id":9}}],["53fe6821-eb11-4c0f-a17e-63a370d54349",{"pageContent":"tweet is hateful or not) and explanations for the reasoning. After\ntesting several variations, we finalize our prompt as follows:\nGiven Post: ‘An Implicit Hateful Tweet’. Answer\nyes or no for whether the post is implicitly hateful.\nExplain why in one sentence.\nSpecifically, “Given Post: ‘An Implicit Hateful Tweet’” is to point\nout what the given tweet is, “Answer yes or no for whether the post\nis implicitly hateful” is to ensure that ChatGPT provides a clear\nanswer for implicit hate classification, and “Explain why in one\nsentence” is to generate a concise explanation for its decision.\nSince ChatGPT does not provide official APIs as of January 2023,\nwe use one of the unofficial APIs\n1\nto collect the ChatGPT responses.\nFor each implicit hate tweet post, we collect three responses from\nChatGPT. As the responses by ChatGPT can be influenced by his-\ntory, we create a new chat session for every implicit hateful tweet\nto ensure no context is provided to ChatGPT. Table 1 shows an\n1","metadata":{"id":10}}],["faf973d0-be6f-485b-9d82-56f95e8ec2c7",{"pageContent":"ChatGPT. As the responses by ChatGPT can be influenced by his-\ntory, we create a new chat session for every implicit hateful tweet\nto ensure no context is provided to ChatGPT. Table 1 shows an\n1\nhttps://github.com/acheong08/ChatGPT\nPromptGiven Post: ‘do you consider identitarianism\nmore of a viable future option than the alt right\nlabel identity evropa seem to be going that way’.\nAnswer yes or no for whether the post is im-\nplicitly hateful. Explain why in one sentence.\nHuman-\nwritten\nNLEs [7]\nnon-white people are enemies\nChatGPT 1It’s unclear.The statement is asking for an\nopinion on a political ideology, \"identitarian-\nism\"  and  a  specific  group,  \"Identity  Evropa\"\nwhich has been known for promoting white\nsupremacist and racist views, but it does not\ncontain any hateful or discriminatory content.\nChatGPT 2Yes.The post is discussing a white supremacist\ngroup and promoting the idea of a white-centric\nfuture, which is a hateful message.\nChatGPT 3No.The post is not necessarily hateful, it is","metadata":{"id":11}}],["152ff48d-0771-4571-a05d-f32e2e07eb4b",{"pageContent":"ChatGPT 2Yes.The post is discussing a white supremacist\ngroup and promoting the idea of a white-centric\nfuture, which is a hateful message.\nChatGPT 3No.The post is not necessarily hateful, it is\ndiscussing the possibility of two different ide-\nologies and asking for opinion on it and not\npromoting any hate towards any group.\nTable 1: Example of our prompt and ChatGPT’s responses\nexample of an input and responses by ChatGPT. We regard the\nYes/No response as the binary classification result and the follow-\ning explanations as the ChatGPT-generated NLE. We notice that,\neven though we try to limit the answer to Yes or No (i.e., “Answer\nyes or no for whether the post is implicitly hateful”), ChatGPT\nsometimes expresses its confusion (e.g., ‘It’s unclear’) when a given\ntweet falls in a gray area.\nFor each tweet post, we aggregate the three responses from\nChatGPT in the following way. We assign a numeric score of +1 to\nYes (i.e., ChatGPT classifies a given post as implicitly hateful), -1 to","metadata":{"id":12}}],["e415e321-d32f-4cd4-aefa-8c96ea3bae15",{"pageContent":"For each tweet post, we aggregate the three responses from\nChatGPT in the following way. We assign a numeric score of +1 to\nYes (i.e., ChatGPT classifies a given post as implicitly hateful), -1 to\nNo (not hateful), and 0 to other responses. We then get the average\nof the three scores and call itChatGPT scoreof a given tweet. We\nlabel a tweet post ‘Hateful’ if the ChatGPT score is greater than 0,\n‘Non-Hateful’ if it is less than 0, and ‘Uncertain’ if it is 0.\n3.3  Human Evaluation\nWe conduct human evaluations to measure the quality of ChatGPT\non the classification task and the generated NLEs.\nQuality of ChatGPT-based Classification.While all our test\ninstances are from the implicit hate tweet dataset, we find that\nChatGPT disagrees (i.e., responding non-hateful or uncertain) for a\nsizable number of tweet posts. Our manual inspection shows that\nthose posts are potentially debatable or extremely implicit/subtle to\nbe hateful. Thus, we turn to re-evaluating those disagreeing cases","metadata":{"id":13}}],["f6d05e86-eb57-4e07-85bb-17172bc54ca5",{"pageContent":"sizable number of tweet posts. Our manual inspection shows that\nthose posts are potentially debatable or extremely implicit/subtle to\nbe hateful. Thus, we turn to re-evaluating those disagreeing cases\nto examine to what extent human agrees with ChatGPT.\nWe annotate the data using Amazon Mechanical Turk (Mturk).\nFor each disagreeing instance, we ask Mturk workers to classify\nwhether a given tweet is hateful, not hateful, or uncertain. We\nfurther design three types of evaluations by providing different\nIs ChatGPT better than Human Annotators?WWW ’23 Companion, April 30-May 4, 2023, Austin, TX, USA\ncontexts. We give a respondent 1) a post only, 2) a post with its\nhuman-written NLE, and 3) a post with its ChatGPT-generated\nNLE. For 3), since we collect three responses from ChatGPT, we\nchoose one NLE from the corresponding label. For example, for a\npost labeled as Non-Hateful by ChatGPT, if it has two NLEs with\nthe answer No and one NLE with the answer Yes, we randomly","metadata":{"id":14}}],["163ecc7b-894c-40ee-8b65-2295778e2700",{"pageContent":"choose one NLE from the corresponding label. For example, for a\npost labeled as Non-Hateful by ChatGPT, if it has two NLEs with\nthe answer No and one NLE with the answer Yes, we randomly\nselect one NLE with the answer No. When a post is labeled Uncer-\ntain, we provide the NLE with a score of 0. We collect the three\nresponses from three different Mturk workers for each instance in\neach evaluation experiment.\nTo ensure the quality of the collected human annotations, we\nrecruit Mturk Masters who: i) have an approval rate greater than\n98%; ii) have more than 5000 HITs approved; and iii) are located in\nthe United States. We also note that no demographic information\nis collected during this process. All the respondents are monetarily\ncompensated at a rate above the minimum hourly wage in the\nUnited States. Since our experiments contain hateful content, we\nprovided extra mental wellness consultant information to prevent\nthe participants from being exposed to unexpected pressures and\ngetting hurt.","metadata":{"id":15}}],["2358c22a-5a49-4dfd-80df-fc858bd24033",{"pageContent":"provided extra mental wellness consultant information to prevent\nthe participants from being exposed to unexpected pressures and\ngetting hurt.\nQuality of ChatGPT-generated Explanation.To evaluate and\ncompare the quality of human-written NLEs and ChatGPT-generated\nones, we useInformativeness[6] andClarity[3], which are com-\nmonly used metrics that reflect the human perception of generated\ntexts. In our context, Informativeness captures the relevance of\nthe NLE in explaining why a tweet would be considered hateful\n(7-point Likert scale ranging from 1 (Completely Not Informative)\nto 7 (Very Informative)). Clarity measures how clear the NLE is\n(7-point Likert scale ranging from 1 (Completely Unclear) to 7 (Very\nClear)).\nIn this evaluation, we randomly sample 100 implicit hateful\ntweets. For each of those 100 cases, we provide a Mturk worker\nwith an original tweet and its corresponding NLE and ask to rate\nthe Informativeness and Clarity of the given NLE. We conduct","metadata":{"id":16}}],["09d233d8-5db3-4cd4-befe-1e3cc20583cb",{"pageContent":"tweets. For each of those 100 cases, we provide a Mturk worker\nwith an original tweet and its corresponding NLE and ask to rate\nthe Informativeness and Clarity of the given NLE. We conduct\ntwo experiments, one with human-written NLEs and another with\nChatGPT-generated NLEs. Since we aim to inspect the general\nquality of the ChatGPT-generated NLEs, we randomly select one\nNLE from the three responses of the ChatGPT.\nWe follow the same procedure as the above Mturk experiment.\nWe also collect three annotations for each tweet-NLE pair. To ensure\nthe quality of responses, we hire experienced research assistants to\nreview them and resolve any disputing cases.\n4  RESULT\n4.1  RQ1: Does ChatGPT detect implicit hateful\ntweets well?\nOur first research question is whether ChatGPT can detect implicit\nhateful tweets well. It is a prerequisite for generating correct and\nquality NLEs. Among the 795 instances from the LatentHatred\ndataset [7], ChatGPT recognizes 636 instances as ‘Implicitly Hateful","metadata":{"id":17}}],["e2f8c174-3122-48c3-9a03-2dba6068a474",{"pageContent":"hateful tweets well. It is a prerequisite for generating correct and\nquality NLEs. Among the 795 instances from the LatentHatred\ndataset [7], ChatGPT recognizes 636 instances as ‘Implicitly Hateful\n(80%) .’ In other words, ChatGPT recognizes 146 instances as ‘Not\nImplicitly Hateful (18.4%)’ and 13 instances as ‘Uncertain (1.6%),’\nwhich conflicts with the original labels in [7]. To examine which is\ncorrect, we conduct a user study explained in§3.3. We ask MTurk\nworkers whether a given post is implicitly hateful but with 1) a\npost only, 2) a post and human-written NLE, and 3) a post and\nChatGPT-generated NLE. Considering the possibility that it is not\nstraightforward to decide whether a given post is hateful or not,\nwe provide the option of ‘Not Sure’ in addition to ‘Yes’ and ‘No.’\nWe collect three responses for each instance.\nSimilar to the computation of the ChatGPT score, we assign +1\nwhen a Mturk worker answers Yes (hateful), -1 when the worker","metadata":{"id":18}}],["ce83a19c-42aa-4cfa-bcf6-5e471d373c0e",{"pageContent":"We collect three responses for each instance.\nSimilar to the computation of the ChatGPT score, we assign +1\nwhen a Mturk worker answers Yes (hateful), -1 when the worker\nanswers No (non-hateful), and 0 otherwise. We compute the mean\nof the three scores for each instance and call theaverage hatefulness\nscore.\nFigure 1: Human evaluation for disagreement between [7]\nand ChatGPT. We give MTurk workers 1) a post only, 2) a\npost and human-written NLE (“post+Human”), and 3) a post\nand ChatGPT-generated NLE (“post+ChatGPT”).\nThere are several interesting observations from the result in\nFigure 1. First, when only a post is given, we find the average hate-\nfulness score is negative (mean: -0.41), which means lay people (i.e.,\nMturk workers) are less likely to consider a tweet hateful when\nChatGPT could not find hate in it. Second, the average hateful-\nness score is negative (mean: -0.52) when a post is given with the\nChatGPT-generated NLE. Interestingly, lay people are more likely","metadata":{"id":19}}],["4a90863f-c841-4cd3-bc44-39dc426d385e",{"pageContent":"ChatGPT could not find hate in it. Second, the average hateful-\nness score is negative (mean: -0.52) when a post is given with the\nChatGPT-generated NLE. Interestingly, lay people are more likely\nto find a given tweet non-hateful when ChatGPT explains why the\ngiven tweet is non-hateful (mean: -0.52) compared to when only a\npost is given (mean: -0.41). The difference is statistically significant,\nconfirmed by the t-test (t(316) = -13.75, p<0.001). Third, the average\nhatefulness score is positive (mean: 0.29) when a post is given with\nthe human-written NLE. This shows that lay people’s decisions\ncan be drifted by the additional explanation; however, the lower\nabsolute score indicates that providing human-written NLE is not\nas convincing as the other two cases.\nConsidering the diversity and nuanced nature of the implicit hate\nspeech [7] and overall toxic behavior online [14], it is not surprising\nthat lay people’s decisions can be affected by additional context.","metadata":{"id":20}}],["db163e4d-1242-408e-851d-107f8c46dd61",{"pageContent":"speech [7] and overall toxic behavior online [14], it is not surprising\nthat lay people’s decisions can be affected by additional context.\nNevertheless, what we observe from the above experiment clearly\ndemonstrates the potential of ChatGPT for nuanced, subjective\ntasks. Lay people tend to agree with ChatGPT that those tweets\nare not likely to be hateful. However, on the other hand, ChatGPT-\ngenerated NLEsreinforcethe human perception. In a case when\nChatGPT’s decision is wrong, such capability might be a danger to\nmisleading lay people and potentially constructing wrong labels.\nIn summary, our answer to RQ1 isyes. ChatGPT shows 80%\nagreement with [7]. Furthermore, for the 20% disagreement cases,\nWWW ’23 Companion, April 30-May 4, 2023, Austin, TX, USAHuang et al.\nlay people are highly likely to lean toward ChatGPT’s classification\nresults.\n4.2  RQ2: Does ChatGPT generate quality NLEs?\nFigure 2: Quality evaluation of human-written NLEs and\nChatGPT-generated NLEs","metadata":{"id":21}}],["a512312a-6ba1-428f-bcf5-1eefc8112968",{"pageContent":"lay people are highly likely to lean toward ChatGPT’s classification\nresults.\n4.2  RQ2: Does ChatGPT generate quality NLEs?\nFigure 2: Quality evaluation of human-written NLEs and\nChatGPT-generated NLEs\nFor the randomly selected 100 instances from our dataset, we col-\nlect the Informativeness and Clarity scores as we explained in§3.3.\nIn Figure 2, ChatGPT-generated NLEs show significantly higher\nClarity scores (mean: 5.39) than human-written NLEs (mean: 4.68).\nAs confirmed by the t-test, the difference is statistically signifi-\ncant (t(197) = -3.73, p < 0.001). However, there is no statistically\nsignificant difference in Informativeness (t(198) = -0.69, p = 0.49).\nOur findings demonstrate that, for end users, both human-written\nNLEs and ChatGPT-generated NLEs provide information to help\nusers identify implicit hatefulness. However, ChatGPT provides\nmore comprehensive illustrations so users can easily confirm im-\nplicit hatefulness from a given tweet.","metadata":{"id":22}}],["a846b803-a738-460f-a159-bcc80b96bd19",{"pageContent":"users identify implicit hatefulness. However, ChatGPT provides\nmore comprehensive illustrations so users can easily confirm im-\nplicit hatefulness from a given tweet.\nIn summary, our answer to RQ2 is alsoyes. ChatGPT generates\nquality NLEs comparable to human annotators for implicit hate\nspeech.\n5  DISCUSSIONS AND CONCLUSION\nIn this paper, we examine ChatGPT-generated NLEs for the implicit\nhateful speech from the perspectives of their accuracy and quality.\nChatGPT correctly identifies 80% of the implicit hateful tweets in\nour experiment setting. The results demonstrate the great potential\nof ChatGPT as a data annotation tool using a simple prompt design.\nFurther studies can be done to investigate the effect of different\nprompt designs. Furthermore, for those 20% disagreement cases,\nour experiments show that ChatGPT’s results are more likely to\nalign with lay people’s perceptions. Moreover, we also find that\nthe ChatGPT-generated NLEs can reinforce human perception, and","metadata":{"id":23}}],["eb470215-5d6d-4f86-9f65-573c7f1fed90",{"pageContent":"our experiments show that ChatGPT’s results are more likely to\nalign with lay people’s perceptions. Moreover, we also find that\nthe ChatGPT-generated NLEs can reinforce human perception, and\nthey tend to be perceived as clearer than human-written NLEs.\nThese results pose an important question. Since ChatGPT can be\nconvincing, its capability would become a risk of misleading lay\npeople if its decision is wrong. This highlights that it would require\nextra caution when using ChatGPT as a tool for assisting data\nannotation.\n6  ETHICAL CONSIDERATIONS\nOur data collection design via Amazon Mechanical Turk (Mturk)\nhas been approved by Singapore Management University (Approval\nNo.: IRB-22-076-A043(622)). To prevent human annotators from\nfeeling offended or having mental discomfort, we highlight the\npossible hatefulness in the headline of the Mturk tasks. We also\nsuggest annotators stop labeling anytime they felt uncomfortable\nand provide the consultant hotlines in our task instructions.\nREFERENCES","metadata":{"id":24}}],["f4465b88-d6aa-4e97-9488-5e74fdd6a839",{"pageContent":"possible hatefulness in the headline of the Mturk tasks. We also\nsuggest annotators stop labeling anytime they felt uncomfortable\nand provide the consultant hotlines in our task instructions.\nREFERENCES\n[1]Jisun An, Haewoon Kwak, Claire Seungeun Lee, Bogang Jun, and Yong-Yeol\nAhn. 2021. Predicting Anti-Asian Hateful Users on Twitter during COVID-19. In\nEMNLP Findings.\n[2]Valerio Basile, Cristina Bosco, Elisabetta Fersini, Debora Nozza, Viviana Patti,\nFrancisco Manuel Rangel Pardo, Paolo Rosso, and Manuela Sanguinetti. 2019.\nSemEval-2019 Task 5: Multilingual Detection of Hate Speech Against Immigrants\nand Women in Twitter. In13th International Workshop on Semantic Evaluation.\n[3]Anja Belz and Eric Kow. 2009. System Building Cost vs. Output Quality in Data-\nto-Text Generation. InProceedings of European Workshop on Natural Language\nGeneration.\n[4]Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom.\n2018. e-SNLI: Natural language inference with natural language explanations. In","metadata":{"id":25}}],["f3b5372f-d684-4d08-96ea-c44d98843d41",{"pageContent":"Generation.\n[4]Oana-Maria Camburu, Tim Rocktäschel, Thomas Lukasiewicz, and Phil Blunsom.\n2018. e-SNLI: Natural language inference with natural language explanations. In\nNeurIPS.\n[5]Ona de Gibert, Naiara Perez, Aitor García-Pablos, and Montse Cuadros. 2018.\nHate Speech Dataset from a White Supremacy Forum. InProceedings of the 2nd\nWorkshop on Abusive Language Online.\n[6]\nOndřej Dušek, Jekaterina Novikova, and Verena Rieser. 2020. Evaluating the state-\nof-the-art of end-to-end natural language generation: The E2E NLG challenge.\nComputer Speech & Language(2020).\n[7]Mai ElSherief, Caleb Ziems, David Muchlinski, Vaishnavi Anupindi, Jordyn Sey-\nbolt, Munmun De Choudhury, and Diyi Yang. 2021. Latent Hatred: A Benchmark\nfor Understanding Implicit Hate Speech. InEMNLP.\n[8]Engadget. 2023. ChatGPT reportedly reached 100 million users in January. https:\n//www.engadget.com/chatgpt-100-million-users-january-130619073.html.\n[9]Aidan  Gilson,  Conrad  Safranek,  Thomas  Huang,  Vimig  Socrates,  Ling  Chi,","metadata":{"id":26}}],["608b300f-d55a-4ce5-ba94-bcefb9ec1be6",{"pageContent":"//www.engadget.com/chatgpt-100-million-users-january-130619073.html.\n[9]Aidan  Gilson,  Conrad  Safranek,  Thomas  Huang,  Vimig  Socrates,  Ling  Chi,\nRichard Andrew Taylor, and David Chartash. 2022. How Well Does ChatGPT Do\nWhen Taking the Medical Licensing Exams? The Implications of Large Language\nModels for Medical Education and Knowledge Assessment.medRxiv(2022),\n2022–12.\n[10]Biyang Guo, Xin Zhang, Ziyuan Wang, Minqi Jiang, Jinran Nie, Yuxuan Ding,\nJianwei Yue, and Yupeng Wu. 2023. How Close is ChatGPT to Human Experts?\nComparison Corpus, Evaluation, and Detection.arXiv:2301.07597(2023).\n[11]\nGabriel Emile Hine, Jeremiah Onaolapo, Emiliano De Cristofaro, Nicolas Kourtel-\nlis, Ilias Leontiadis, Riginos Samaras, Gianluca Stringhini, and Jeremy Blackburn.\n2017.  Kek, cucks, and god emperor trump: A measurement study of 4chan’s\npolitically incorrect forum and its effects on the web. InICWSM.\n[12]\nFan Huang, Haewoon Kwak, and Jisun An. 2023.  Chain of Explanation: New","metadata":{"id":27}}],["1e537c59-b147-4d30-a7fe-884fb4e1baa4",{"pageContent":"politically incorrect forum and its effects on the web. InICWSM.\n[12]\nFan Huang, Haewoon Kwak, and Jisun An. 2023.  Chain of Explanation: New\nPrompting Method to Generate Higher Quality Natural Language Explanation\nfor Implicit Hate Speech. InCompanion Proceedings of the ACM Web Conference.\n[13]Katharina  Jeblick,  Balthasar  Schachtner,  Jakob  Dexl,  Andreas  Mittermeier,\nAnna Theresa Stüber, Johanna Topalis, Tobias Weber, Philipp Wesp, Bastian\nSabel, Jens Ricke, et al.2022.  ChatGPT Makes Medicine Easy to Swallow: An\nExploratory Case Study on Simplified Radiology Reports.arXiv:2212.14882(2022).\n[14]Haewoon Kwak, Jeremy Blackburn, and Seungyeop Han. 2015. Exploring cyber-\nbullying and other toxic behavior in team competition online games. InProceed-\nings of the 33rd annual ACM conference on human factors in computing systems.\n[15]OpenAI. 2022. ChatGPT: Optimizing Language Model for Dialogue.OpenAI blog\n(2022).\n[16]Joni Salminen, Hind Almerekhi, Milica Milenković, Soon-gyo Jung, Jisun An,","metadata":{"id":28}}],["75345e06-7b39-4745-929f-5dff8327146e",{"pageContent":"[15]OpenAI. 2022. ChatGPT: Optimizing Language Model for Dialogue.OpenAI blog\n(2022).\n[16]Joni Salminen, Hind Almerekhi, Milica Milenković, Soon-gyo Jung, Jisun An,\nHaewoon Kwak, and Bernard J Jansen. 2018. Anatomy of online hate: developing\na taxonomy and machine learning models for identifying and classifying hate in\nonline news media. InICWSM.\n[17]Maarten Sap, Saadia Gabriel, Lianhui Qin, Dan Jurafsky, Noah A. Smith, and Yejin\nChoi. 2020. Social Bias Frames: Reasoning about Social and Power Implications\nof Language. InACL.\n[18]Dominik Sobania, Martin Briesch, Carol Hanna, and Justyna Petke. 2023.  An\nAnalysis of the Automatic Bug Fixing Performance of ChatGPT.arXiv:2301.08653\n(2023).\n[19]\nRohit Sridhar and Diyi Yang. 2022.  Explaining Toxic Text via Knowledge En-\nhanced Text Generation. InNAACL.\n[20]Bowen Zhang, Daijun Ding, and Liwen Jing. 2022. How would Stance Detection\nTechniques Evolve after the Launch of ChatGPT?arXiv:2212.14548(2022).","metadata":{"id":29}}]],{"0":"f7e7bc92-9907-41de-bd8c-fd0756399619","1":"a0cbed60-9e06-4888-b2f9-a4631c6276c2","2":"f4c14482-1dfc-484c-938b-0d6d28f7dbbd","3":"c33e8fc0-015a-4ad0-8105-b0cb4b533942","4":"e57fa63b-7c3b-4580-82c1-d11b49e3363a","5":"0a3e32b5-141a-46dc-9a7a-3e52c816b585","6":"769501ad-701c-47ff-94b1-e7bf4c3c5d17","7":"daf32c68-b0aa-4693-ae21-3795991102b8","8":"77eb8b69-0717-436a-be6e-ed6387fdc365","9":"93cea19a-2fd7-40c4-9e69-a9b88931eb9a","10":"53fe6821-eb11-4c0f-a17e-63a370d54349","11":"faf973d0-be6f-485b-9d82-56f95e8ec2c7","12":"152ff48d-0771-4571-a05d-f32e2e07eb4b","13":"e415e321-d32f-4cd4-aefa-8c96ea3bae15","14":"f6d05e86-eb57-4e07-85bb-17172bc54ca5","15":"163ecc7b-894c-40ee-8b65-2295778e2700","16":"2358c22a-5a49-4dfd-80df-fc858bd24033","17":"09d233d8-5db3-4cd4-befe-1e3cc20583cb","18":"e2f8c174-3122-48c3-9a03-2dba6068a474","19":"ce83a19c-42aa-4cfa-bcf6-5e471d373c0e","20":"4a90863f-c841-4cd3-bc44-39dc426d385e","21":"db163e4d-1242-408e-851d-107f8c46dd61","22":"a512312a-6ba1-428f-bcf5-1eefc8112968","23":"a846b803-a738-460f-a159-bcc80b96bd19","24":"eb470215-5d6d-4f86-9f65-573c7f1fed90","25":"f4465b88-d6aa-4e97-9488-5e74fdd6a839","26":"f3b5372f-d684-4d08-96ea-c44d98843d41","27":"608b300f-d55a-4ce5-ba94-bcefb9ec1be6","28":"1e537c59-b147-4d30-a7fe-884fb4e1baa4","29":"75345e06-7b39-4745-929f-5dff8327146e"}]